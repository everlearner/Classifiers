{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron_dataset_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TetYtCjcVq3B"
      },
      "source": [
        "\"\"\" Team Members\r\n",
        "    Godhala Meganaa 2017B3A70973H\r\n",
        "    Keshav Kabra 2018AAPS0527H\r\n",
        "    Rohan Maheshwari 2017B4A70965H\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "files.upload()\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import csv\r\n",
        "import json\r\n",
        "\r\n",
        "data =pd.read_csv('train2.txt',header=None,sep=\" \")\r\n",
        "#print(data)\r\n",
        "Y_train=list()\r\n",
        "#print(Y_train)\r\n",
        "#print(\"yes\")\r\n",
        "X=[]\r\n",
        "temp=[]\r\n",
        "\r\n",
        "rows=len(data)\r\n",
        "cols=len(data.columns)\r\n",
        "\r\n",
        "X_train=list(list())\r\n",
        "z=[[]*(cols-1)]*(rows)\r\n",
        "\r\n",
        "#convert string data to float\r\n",
        "for i in range(cols):\r\n",
        "  data[i]=data[i].astype(float)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "data.to_json(r'train2.json',orient='values')\r\n",
        "files.download('train2.json')\r\n",
        "\r\n",
        "\"\"\"for i in range(rows):\r\n",
        "  for j in range(cols):\r\n",
        "    print(data[i][j])\"\"\"\r\n",
        "\r\n",
        "\r\n",
        "with open('train2.json') as f:\r\n",
        "  X= json.load(f)\r\n",
        "#print(X)\r\n",
        "X_train=X\r\n",
        "for i in range(rows):\r\n",
        "    Y_train.append(X[i][cols-1])\r\n",
        "\r\n",
        "#for i in X_train:\r\n",
        "#  del i[cols-1]\r\n",
        "\r\n",
        "#print(X)\r\n",
        "#print(Y_train)    \r\n",
        "\r\n",
        "#making X and Y are done\r\n",
        "#import numpy as np\r\n",
        "import csv\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "# notice that you should run it only with python3\r\n",
        "\"\"\" define a class to generate weights for perceptron\"\"\"\r\n",
        "\r\n",
        "class Perceptron(object):\r\n",
        "\r\n",
        "    def __init__(self, no_of_inputs, lr_rate=0.5, bios_lr_rate=0.5):\r\n",
        "    #\"\"\"\r\n",
        "    # @param: the object of perceptron,no of inputs,learning rate,bios_learning rate\r\n",
        "    # returns : initialises the object with the given parameters\r\n",
        "    #\"\"\"\r\n",
        "\r\n",
        "        # self.threshold = threshold\r\n",
        "        self.lr_rate = lr_rate\r\n",
        "        self.bios_lr_rate = bios_lr_rate\r\n",
        "        self.weights = [0.0,0.0,0.0,0.0,0.0]\r\n",
        "           \r\n",
        "    def getter(self):\r\n",
        "      #\"\"\"@param : object of perceptron class\r\n",
        "      #    returns: vector of weights\"\"\"\r\n",
        "        return self.weights\r\n",
        "\r\n",
        "    def train(self, training_inputs, target):\r\n",
        "      #\"\"\"@param : object of perceptron, X-vector, target value\r\n",
        "      #  role : alters the weights and uses stochastic gradient descent approach to find the optimal weights\r\n",
        "      #  returns : the predicted value of target\"\"\"\r\n",
        "        # print(training_inputs)\r\n",
        "        group1_x  = training_inputs[0]\r\n",
        "        x2 = training_inputs[1]\r\n",
        "        x3 = training_inputs[2]\r\n",
        "        x4 = training_inputs[3]\r\n",
        "        b = self.weights[4]\r\n",
        "        w1 = self.weights[0]\r\n",
        "        w2 = self.weights[1]\r\n",
        "        w3 = self.weights[2]\r\n",
        "        w4 = self.weights[3]\r\n",
        "        \r\n",
        "        y = b + group1_x * w1 + x2 * w2 + x3*w3 + x4*w4\r\n",
        "\r\n",
        "        if y > 0:\r\n",
        "            y = 1.0\r\n",
        "        else:\r\n",
        "            y = 0.0\r\n",
        "        self.weights[4] = b + self.bios_lr_rate * (target - y)\r\n",
        "        self.weights[3] = w4 + self.lr_rate * (target - y)*x4\r\n",
        "        self.weights[2] = w3 + self.lr_rate * (target - y)*x3\r\n",
        "        self.weights[0] = w1 + self.lr_rate * (target - y) * group1_x\r\n",
        "        self.weights[1] = w2 + self.lr_rate * (target - y) * x2\r\n",
        "        return y\r\n",
        "\r\n",
        "\r\n",
        "network = Perceptron(4)\r\n",
        "training_inputs = []\r\n",
        "label = []\r\n",
        "group0_x = []\r\n",
        "group0_y = []\r\n",
        "group1_x = []\r\n",
        "group1_y = []\r\n",
        "iterations = 10000\r\n",
        "num_of_miss = {}\r\n",
        "accuracy_of_each_iteration = {}\r\n",
        "miss = 0\r\n",
        "\"\"\" Run the updated training weights on each point and find for missclassifications and alter the weights until you reach zero missclassifications\"\"\"\r\n",
        "for i in range(iterations):\r\n",
        "\r\n",
        "        for row in X:\r\n",
        "            training_inputs = [float(row[0]),float(row[1]),float(row[2]),float(row[3])]\r\n",
        "            label = float(row[4])\r\n",
        "            prediction = network.train(training_inputs, label)\r\n",
        "            if prediction != label:\r\n",
        "                miss += 1\r\n",
        "    \r\n",
        "            if label == 1.0:\r\n",
        "              #\"\"\"when you find the positive point , append it to the positive group\"\"\"\r\n",
        "                group1_x.append(float(row[0]))\r\n",
        "                group1_y.append(float(row[1]))\r\n",
        "            if label == 0.0:\r\n",
        "              #\"\"\"when you find the negative point , append it to the negative group\"\"\"\r\n",
        "                group0_x.append(float(row[0]))\r\n",
        "                group0_y.append(float(row[1]))\r\n",
        "        print(\"no of misses are %d\",miss)\r\n",
        "        #\"\"\"update the number of misses for each iteration\"\"\"\r\n",
        "        num_of_miss[i] = miss\r\n",
        "        #\"\"\"terminating or converging condition is reached when all the points are classified correctly\"\"\"\r\n",
        "        if num_of_miss[i]==0:\r\n",
        "          #print(\"linearly separable at iteration\",i)\r\n",
        "          break\r\n",
        "        if num_of_miss[i]==2:\r\n",
        "          break\r\n",
        "        accuracy_of_each_iteration[i] = ((rows-num_of_miss[i])/rows)*100\r\n",
        "        print(\"accuracy of iteration %d-----> %f \"%(i,accuracy_of_each_iteration[i]))\r\n",
        "        print(\"loss of iteration is %f \"%(i,(((num_of_miss[i])/rows)*100)))\r\n",
        "        print()\r\n",
        "        miss = 0\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "weights = network.getter()\r\n",
        "w1 = weights[0]\r\n",
        "w2 = weights[1]\r\n",
        "w3 = weights[2]\r\n",
        "w4 = weights[3]\r\n",
        "b = weights[4]\r\n",
        "\r\n",
        "print(b)\r\n",
        "print(w1)\r\n",
        "print(w2)\r\n",
        "print(w3)\r\n",
        "print(w4)\r\n",
        "\r\n",
        "#files.upload()\r\n",
        "test_data =pd.read_csv('test2.txt',header=None,sep=\" \")\r\n",
        "\r\n",
        "\r\n",
        "test_rows=len(test_data)\r\n",
        "test_cols=len(test_data.columns)\r\n",
        "\r\n",
        "#convert string data to float\r\n",
        "for i in range(test_cols):\r\n",
        "  test_data[i]=test_data[i].astype(float)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "test_data.to_json(r'test2.json',orient='values')\r\n",
        "files.download('test2.json')\r\n",
        "\r\n",
        "\"\"\"for i in range(rows):\r\n",
        "  for j in range(cols):\r\n",
        "    print(data[i][j])\"\"\"\r\n",
        "\r\n",
        "\r\n",
        "with open('test2.json') as f1:\r\n",
        "  test_X= json.load(f1)\r\n",
        "\r\n",
        "#files.download('test1.json')\r\n",
        "\r\n",
        "test_miss=0\r\n",
        "\r\n",
        "for row in test_X:\r\n",
        "    y1 = b + float(row[0])*w1 + float(row[1])*w2 + float(row[2])*w3 + float(row[3])*w4\r\n",
        "\r\n",
        "    if y1 > 0:\r\n",
        "      y1 = 1.0\r\n",
        "    else:\r\n",
        "      y1 = 0.0\r\n",
        "    \r\n",
        "    label1=float(row[4])\r\n",
        "    if y1 != label1:\r\n",
        "      test_miss = test_miss+1\r\n",
        "\r\n",
        "test_accuracy=(test_rows-test_miss)*100/test_rows\r\n",
        "print(\"printing test accuracy\")\r\n",
        "print(test_accuracy)\r\n",
        "        \r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIGZocc_nfca"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}