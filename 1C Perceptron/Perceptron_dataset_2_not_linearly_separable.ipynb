{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "TetYtCjcVq3B",
    "outputId": "cd08c050-a12a-40d0-9909-bad93a95b22e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-a518c987-f272-42b0-b9cb-12a9bd8ead59\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-a518c987-f272-42b0-b9cb-12a9bd8ead59\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_9092e3eb-baf9-4bd2-87e7-a658f815a4a9\", \"train2.json\", 35619)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.7767, 9.7794, -3.9075, -3.5323, 0.0], [3.4769, -0.15314, 2.53, 2.4495, 0.0], [1.9818, 9.2621, -3.521, -1.872, 0.0], [3.8023, -3.8696, 4.044, 0.95343, 0.0], [4.3483, 11.1079, -4.0857, -4.2539, 0.0], [1.1518, 1.3864, 5.2727, -0.43536, 0.0], [-1.2576, 1.5892, 7.0078, 0.42455, 0.0], [1.9572, -5.1153, 8.6127, -1.4297, 0.0], [-2.484, 12.1611, 2.8204, -3.7418, 0.0], [-1.1497, 1.2954, 7.701, 0.62627, 0.0], [4.8368, 10.0132, -4.3239, -4.3276, 0.0], [-0.12196, 8.8068, 0.94566, -4.2267, 0.0], [1.9429, 6.3961, 0.092248, 0.58102, 0.0], [1.742, -4.809, 8.2142, -2.0659, 0.0], [-1.5222, 10.8409, 2.7827, -4.0974, 0.0], [-1.3, 10.2678, -2.953, -5.8638, 0.0], [3.4246, -0.14693, 0.80342, 0.29136, 0.0], [2.5503, -4.9518, 6.3729, -0.41596, 0.0], [1.5691, 6.3465, -0.1828, -2.4099, 0.0], [1.3087, 4.9228, 2.0013, 0.22024, 0.0], [5.1776, 8.2316, -3.2511, -1.5694, 0.0], [2.229, 9.6325, -3.1123, -2.7164, 0.0], [5.6272, 10.0857, -4.2931, -3.8142, 0.0], [1.2138, 8.7986, -2.1672, -0.74182, 0.0], [0.3798, 0.7098, 0.7572, -0.4444, 0.0], [0.5415, 6.0319, 1.6825, -0.46122, 0.0], [4.0524, 5.6802, -1.9693, 0.026279, 0.0], [4.7285, 2.1065, -0.28305, 1.5625, 0.0], [3.4359, 0.66216, 2.1041, 1.8922, 0.0], [0.86816, 10.2429, -1.4912, -4.0082, 0.0], [3.359, 9.8022, -3.8209, -3.7133, 0.0], [3.6702, 2.9942, 0.85141, 0.30688, 0.0], [1.3349, 6.1189, 0.46497, 0.49826, 0.0], [3.1887, -3.4143, 2.7742, -0.2026, 0.0], [2.4527, 2.9653, 0.20021, -0.056479, 0.0], [3.9121, 2.9735, 0.92852, 0.60558, 0.0], [3.9364, 10.5885, -3.725, -4.3133, 0.0], [3.9414, -3.2902, 3.1674, 1.0866, 0.0], [3.6922, -3.9585, 4.3439, 1.3517, 0.0], [5.681, 7.795, -2.6848, -0.92544, 0.0], [0.77124, 9.0862, -1.2281, -1.4996, 0.0], [3.5761, 9.7753, -3.9795, -3.4638, 0.0], [1.602, 6.1251, 0.52924, 0.47886, 0.0], [2.6682, 10.216, -3.4414, -4.0069, 0.0], [2.0007, 1.8644, 2.6491, 0.47369, 0.0], [0.64215, 3.1287, 4.2933, 0.64696, 0.0], [4.3848, -3.0729, 3.0423, 1.2741, 0.0], [0.77445, 9.0552, -2.4089, -1.3884, 0.0], [0.96574, 8.393, -1.361, -1.4659, 0.0], [3.0948, 8.7324, -2.9007, -0.96682, 0.0], [4.9362, 7.6046, -2.3429, -0.85302, 0.0], [-1.9458, 11.2217, 1.9079, -3.4405, 0.0], [5.7403, -0.44284, 0.38015, 1.3763, 0.0], [-2.6989, 12.1984, 0.67661, -8.5482, 0.0], [1.1472, 3.5985, 1.9387, -0.43406, 0.0], [2.9742, 8.96, -2.9024, -1.0379, 0.0], [4.5707, 7.2094, -3.2794, -1.4944, 0.0], [0.1848, 6.5079, 2.0133, -0.87242, 0.0], [0.87256, 9.2931, -0.7843, -2.1978, 0.0], [0.39559, 6.8866, 1.0588, -0.67587, 0.0], [3.8384, 6.1851, -2.0439, -0.033204, 0.0], [2.8209, 7.3108, -0.81857, -1.8784, 0.0], [2.5817, 9.7546, -3.1749, -2.9957, 0.0], [3.8213, 0.23175, 2.0133, 2.0564, 0.0], [0.3798, 0.7098, 0.7572, -0.4444, 0.0], [3.4893, 6.69, -1.2042, -0.38751, 0.0], [-1.7781, 0.8546, 7.1303, 0.027572, 0.0], [2.0962, 2.4769, 1.9379, -0.040962, 0.0], [0.94732, -0.57113, 7.1903, -0.67587, 0.0], [2.8261, 9.4007, -3.3034, -1.0509, 0.0], [0.0071249, 8.3661, 0.50781, -3.8155, 0.0], [0.96788, 7.1907, 1.2798, -2.4565, 0.0], [4.7432, 2.1086, 0.1368, 1.6543, 0.0], [3.6575, 7.2797, -2.2692, -1.144, 0.0], [3.8832, 6.4023, -2.432, -0.98363, 0.0], [3.4776, 8.811, -3.1886, -0.92285, 0.0], [1.1315, 7.9212, 1.093, -2.8444, 0.0], [2.8237, 2.8597, 0.19678, 0.57196, 0.0], [1.9321, 6.0423, 0.26019, -2.053, 0.0], [3.0632, -3.3315, 5.1305, 0.8267, 0.0], [-1.8411, 10.8306, 2.769, -3.0901, 0.0], [2.8084, 11.3045, -3.3394, -4.4194, 0.0], [2.5698, -4.4076, 5.9856, 0.078002, 0.0], [-0.12624, 10.3216, -3.7121, -6.1185, 0.0], [3.3756, -4.0951, 4.367, 1.0698, 0.0], [-0.048008, -1.6037, 8.4756, 0.75558, 0.0], [0.5706, -0.0248, 1.2421, -0.5621, 0.0], [0.88444, 6.5906, 0.55837, -0.44182, 0.0], [3.8644, 3.7061, 0.70403, 0.35214, 0.0], [1.2999, 2.5762, 2.0107, -0.18967, 0.0], [2.0051, -6.8638, 8.132, -0.2401, 0.0], [4.9294, 0.27727, 0.20792, 0.33662, 0.0], [2.8297, 6.3485, -0.73546, -0.58665, 0.0], [2.565, 8.633, -2.9941, -1.3082, 0.0], [2.093, 8.3061, 0.022844, -3.2724, 0.0], [4.6014, 5.6264, -2.1235, 0.19309, 0.0], [5.0617, -0.35799, 0.44698, 0.99868, 0.0], [-0.2951, 9.0489, -0.52725, -2.0789, 0.0], [3.577, 2.4004, 1.8908, 0.73231, 0.0], [3.9433, 2.5017, 1.5215, 0.903, 0.0], [2.6648, 10.754, -3.3994, -4.1685, 0.0], [5.9374, 6.1664, -2.5905, -0.36553, 0.0], [2.0153, 1.8479, 3.1375, 0.42843, 0.0], [5.8782, 5.9409, -2.8544, -0.60863, 0.0], [-2.3983, 12.606, 2.9464, -5.7888, 0.0], [1.762, 4.3682, 2.1384, 0.75429, 0.0], [4.2406, -2.4852, 1.608, 0.7155, 0.0], [3.4669, 6.87, -1.0568, -0.73147, 0.0], [3.1896, 5.7526, -0.18537, -0.30087, 0.0], [0.81356, 9.1566, -2.1492, -4.1814, 0.0], [0.52855, 0.96427, 4.0243, -1.0483, 0.0], [2.1319, -2.0403, 2.5574, -0.061652, 0.0], [0.33111, 4.5731, 2.057, -0.18967, 0.0], [1.2746, 8.8172, -1.5323, -1.7957, 0.0], [2.2091, 7.4556, -1.3284, -3.3021, 0.0], [2.5328, 7.528, -0.41929, -2.6478, 0.0], [3.6244, 1.4609, 1.3501, 1.9284, 0.0], [-1.3885, 12.5026, 0.69118, -7.5487, 0.0], [5.7227, 5.8312, -2.4097, -0.24527, 0.0], [3.3583, 10.3567, -3.7301, -3.6991, 0.0], [2.5227, 2.2369, 2.7236, 0.79438, 0.0], [0.045304, 6.7334, 1.0708, -0.9332, 0.0], [4.8278, 7.7598, -2.4491, -1.2216, 0.0], [1.9476, -4.7738, 8.527, -1.8668, 0.0], [2.7659, 0.66216, 4.1494, -0.28406, 0.0], [-0.10648, -0.76771, 7.7575, 0.64179, 0.0], [0.72252, -0.053811, 5.6703, -1.3509, 0.0], [4.2475, 1.4816, -0.48355, 0.95343, 0.0], [3.9772, 0.33521, 2.2566, 2.1625, 0.0], [3.6667, 4.302, 0.55923, 0.33791, 0.0], [2.8232, 10.8513, -3.1466, -3.9784, 0.0], [-1.4217, 11.6542, -0.057699, -7.1025, 0.0], [4.2458, 1.1981, 0.66633, 0.94696, 0.0], [4.1038, -4.8069, 3.3491, -0.49225, 0.0], [1.4507, 8.7903, -2.2324, -0.65259, 0.0], [3.4647, -3.9172, 3.9746, 0.36119, 0.0], [1.8533, 6.1458, 1.0176, -2.0401, 0.0], [3.5288, 0.71596, 1.9507, 1.9375, 0.0], [3.9719, 1.0367, 0.75973, 1.0013, 0.0], [3.534, 9.3614, -3.6316, -1.2461, 0.0], [3.6894, 9.887, -4.0788, -4.3664, 0.0], [3.0672, -4.4117, 3.8238, -0.81682, 0.0], [2.6463, -4.8152, 6.3549, 0.003003, 0.0], [2.2893, 3.733, 0.6312, -0.39786, 0.0], [1.5673, 7.9274, -0.056842, -2.1694, 0.0], [4.0405, 0.51524, 1.0279, 1.106, 0.0], [4.3846, -4.8794, 3.3662, -0.029324, 0.0], [2.0165, -0.25246, 5.1707, 1.0763, 0.0], [4.0446, 11.1741, -4.3582, -4.7401, 0.0], [-0.33729, -0.64976, 7.6659, 0.72326, 0.0], [-2.4604, 12.7302, 0.91738, -7.6418, 0.0], [4.1195, 10.9258, -3.8929, -4.1802, 0.0], [2.0193, 0.82356, 4.6369, 1.4202, 0.0], [1.5701, 7.9129, 0.29018, -2.1953, 0.0], [2.6415, 7.586, -0.28562, -1.6677, 0.0], [5.0214, 8.0764, -3.0515, -1.7155, 0.0], [4.3435, 3.3295, 0.83598, 0.64955, 0.0], [1.8238, -6.7748, 8.3873, -0.54139, 0.0], [3.9382, 0.9291, 0.78543, 0.6767, 0.0], [2.2517, -5.1422, 4.2916, -1.2487, 0.0], [5.504, 10.3671, -4.413, -4.0211, 0.0], [2.8521, 9.171, -3.6461, -1.2047, 0.0], [1.1676, 9.1566, -2.0867, -0.80647, 0.0], [2.6104, 8.0081, -0.23592, -1.7608, 0.0], [0.32444, 10.067, -1.1982, -4.1284, 0.0], [3.8962, -4.7904, 3.3954, -0.53751, 0.0], [2.1752, -0.8091, 5.1022, -0.67975, 0.0], [1.1588, 8.9331, -2.0807, -1.1272, 0.0], [4.7072, 8.2957, -2.5605, -1.4905, 0.0], [-1.9667, 11.8052, -0.40472, -7.8719, 0.0], [4.0552, 0.40143, 1.4563, 0.65343, 0.0], [2.3678, -6.839, 8.4207, -0.44829, 0.0], [0.33565, 6.8369, 0.69718, -0.55691, 0.0], [4.3398, -5.3036, 3.8803, -0.70432, 0.0], [1.5456, 8.5482, 0.4187, -2.1784, 0.0], [1.4276, 8.3847, -2.0995, -1.9677, 0.0], [-0.27802, 8.1881, -3.1338, -2.5276, 0.0], [0.93611, 8.6413, -1.6351, -1.3043, 0.0], [4.6352, -3.0087, 2.6773, 1.212, 0.0], [1.5268, -5.5871, 8.6564, -1.722, 0.0], [0.95626, 2.4728, 4.4578, 0.21636, 0.0], [-2.7914, 1.7734, 6.7756, -0.39915, 0.0], [5.2032, 3.5116, -1.2538, 1.0129, 0.0], [3.1836, 7.2321, -1.0713, -2.5909, 0.0], [0.65497, 5.1815, 1.0673, -0.42113, 0.0], [5.6084, 10.3009, -4.8003, -4.3534, 0.0], [1.105, 7.4432, 0.41099, -3.0332, 0.0], [3.9292, -2.9156, 2.2129, 0.30817, 0.0], [1.1558, 6.4003, 1.5506, 0.6961, 0.0], [2.5581, 2.6218, 1.8513, 0.40257, 0.0], [2.7831, 10.9796, -3.557, -4.4039, 0.0], [3.7635, 2.7811, 0.66119, 0.34179, 0.0], [-2.6479, 10.1374, -1.331, -5.4707, 0.0], [1.0652, 8.3682, -1.4004, -1.6509, 0.0], [-1.4275, 11.8797, 0.41613, -6.9978, 0.0], [5.7456, 10.1808, -4.7857, -4.3366, 0.0], [5.086, 3.2798, -1.2701, 1.1189, 0.0], [3.4092, 5.4049, -2.5228, -0.89958, 0.0], [-0.2361, 9.3221, 2.1307, -4.3793, 0.0], [3.8197, 8.9951, -4.383, -4.0327, 0.0], [-1.1391, 1.8127, 6.9144, 0.70127, 0.0], [4.9249, 0.68906, 0.77344, 1.2095, 0.0], [2.5089, 6.841, -0.029423, 0.44912, 0.0], [-0.2062, 9.2207, -3.7044, -6.8103, 0.0], [3.946, 6.8514, -1.5443, -0.5582, 0.0], [-0.278, 8.1881, -3.1338, -2.5276, 0.0], [1.8592, 3.2074, -0.15966, -0.26208, 0.0], [0.56953, 7.6294, 1.5754, -3.2233, 0.0], [3.4626, -4.449, 3.5427, 0.15429, 0.0], [3.3951, 1.1484, 2.1401, 2.0862, 0.0], [5.0429, -0.52974, 0.50439, 1.106, 0.0], [3.7758, 7.1783, -1.5195, 0.40128, 0.0], [4.6562, 7.6398, -2.4243, -1.2384, 0.0], [4.0948, -2.9674, 2.3689, 0.75429, 0.0], [1.8384, 6.063, 0.54723, 0.51248, 0.0], [2.0153, 0.43661, 4.5864, -0.3151, 0.0], [3.5251, 0.7201, 1.6928, 0.64438, 0.0], [3.757, -5.4236, 3.8255, -1.2526, 0.0], [2.5989, 3.5178, 0.7623, 0.81119, 0.0], [1.8994, 0.97462, 4.2265, 0.81377, 0.0], [3.6941, -3.9482, 4.2625, 1.1577, 0.0], [4.4295, -2.3507, 1.7048, 0.90946, 0.0], [6.8248, 5.2187, -2.5425, 0.5461, 0.0], [1.8967, -2.5163, 2.8093, -0.79742, 0.0], [2.1526, -6.1665, 8.0831, -0.34355, 0.0], [3.3004, 7.0811, -1.3258, 0.22283, 0.0], [2.7213, 7.05, -0.58808, 0.41809, 0.0], [3.8846, -3.0336, 2.5334, 0.20214, 0.0], [4.1665, -0.4449, 0.23448, 0.27843, 0.0], [0.94225, 5.8561, 1.8762, -0.32544, 0.0], [5.1321, -0.031048, 0.32616, 1.1151, 0.0], [0.38251, 6.8121, 1.8128, -0.61251, 0.0], [3.0333, -2.5928, 2.3183, 0.303, 0.0], [2.9233, 6.0464, -0.11168, -0.58665, 0.0], [1.162, 10.2926, -1.2821, -4.0392, 0.0], [3.7791, 2.5762, 1.3098, 0.5655, 0.0], [0.77765, 5.9781, 1.1941, -0.3526, 0.0], [-0.38388, -1.0471, 8.0514, 0.49567, 0.0], [0.21084, 9.4359, -0.094543, -1.859, 0.0], [2.9571, -4.5938, 5.9068, 0.57196, 0.0], [4.6439, -3.3729, 2.5976, 0.55257, 0.0], [3.3577, -4.3062, 6.0241, 0.18274, 0.0], [3.5127, 2.9073, 1.0579, 0.40774, 0.0], [2.6562, 10.7044, -3.3085, -4.0767, 0.0], [-1.3612, 10.694, 1.7022, -2.9026, 0.0], [-0.278, 8.1881, -3.1338, -2.5276, 0.0], [1.04, -6.9321, 8.2888, -1.2991, 0.0], [2.1881, 2.7356, 1.3278, -0.1832, 0.0], [4.2756, -2.6528, 2.1375, 0.94437, 0.0], [-0.11996, 6.8741, 0.91995, -0.6694, 0.0], [2.9736, 8.7944, -3.6359, -1.3754, 0.0], [3.7798, -3.3109, 2.6491, 0.066365, 0.0], [5.3586, 3.7557, -1.7345, 1.0789, 0.0], [1.8373, 6.1292, 0.84027, 0.55257, 0.0], [1.2262, 0.89599, 5.7568, -0.11596, 0.0], [-0.048008, -0.56078, 7.7215, 0.453, 0.0], [0.5706, -0.024841, 1.2421, -0.56208, 0.0], [4.3634, 0.46351, 1.4281, 2.0202, 0.0], [3.482, -4.1634, 3.5008, -0.078462, 0.0], [0.51947, -3.2633, 3.0895, -0.98492, 0.0], [2.3164, -2.628, 3.1529, -0.08622, 0.0], [-1.8348, 11.0334, 3.1863, -4.8888, 0.0], [1.3754, 8.8793, -1.9136, -0.53751, 0.0], [-0.16682, 5.8974, 0.49839, -0.70044, 0.0], [0.29961, 7.1328, -0.31475, -1.1828, 0.0], [0.25035, 9.3262, -3.6873, -6.2543, 0.0], [2.4673, 1.3926, 1.7125, 0.41421, 0.0], [0.77805, 6.6424, -1.1425, -1.0573, 0.0], [3.4465, 2.9508, 1.0271, 0.5461, 0.0], [2.2429, -4.1427, 5.2333, -0.40173, 0.0], [3.7321, -3.884, 3.3577, -0.0060486, 0.0], [4.3365, -3.584, 3.6884, 0.74912, 0.0], [-2.0759, 10.8223, 2.6439, -4.837, 0.0], [4.0715, 7.6398, -2.0824, -1.1698, 0.0], [0.76163, 5.8209, 1.1959, -0.64613, 0.0], [-0.53966, 7.3273, 0.46583, -1.4543, 0.0], [2.6213, 5.7919, 0.065686, -1.5759, 0.0], [3.0242, -3.3378, 2.5865, -0.54785, 0.0], [5.8519, 5.3905, -2.4037, -0.061652, 0.0], [0.5706, -0.0248, 1.2421, -0.5621, 0.0], [3.9771, 11.1513, -3.9272, -4.3444, 0.0], [1.5478, 9.1814, -1.6326, -1.7375, 0.0], [0.74054, 0.36625, 2.1992, 0.48403, 0.0], [0.49571, 10.2243, -1.097, -4.0159, 0.0], [1.645, 7.8612, -0.87598, -3.5569, 0.0], [3.6077, 6.8576, -1.1622, 0.28231, 0.0], [3.2403, -3.7082, 5.2804, 0.41291, 0.0], [3.9166, 10.2491, -4.0926, -4.4659, 0.0], [3.9262, 6.0299, -2.0156, -0.065531, 0.0], [5.591, 10.4643, -4.3839, -4.3379, 0.0], [3.7522, -3.6978, 3.9943, 1.3051, 0.0], [1.3114, 4.5462, 2.2935, 0.22541, 0.0], [3.7022, 6.9942, -1.8511, -0.12889, 0.0], [4.364, -3.1039, 2.3757, 0.78532, 0.0], [3.5829, 1.4423, 1.0219, 1.4008, 0.0], [4.65, -4.8297, 3.4553, -0.25174, 0.0], [5.1731, 3.9606, -1.983, 0.40774, 0.0], [3.2692, 3.4184, 0.20706, -0.066824, 0.0], [2.4012, 1.6223, 3.0312, 0.71679, 0.0], [1.7257, -4.4697, 8.2219, -1.8073, 0.0], [4.7965, 6.9859, -1.9967, -0.35001, 0.0], [4.0962, 10.1891, -3.9323, -4.1827, 0.0], [2.5559, 3.3605, 2.0321, 0.26809, 0.0], [3.4916, 8.5709, -3.0326, -0.59182, 0.0], [0.5195, -3.2633, 3.0895, -0.9849, 0.0], [2.9856, 7.2673, -0.409, -2.2431, 0.0], [4.0932, 5.4132, -1.8219, 0.23576, 0.0], [1.7748, -0.76978, 5.5854, 1.3039, 0.0], [5.2012, 0.32694, 0.17965, 1.1797, 0.0], [-0.45062, -1.3678, 7.0858, -0.40303, 0.0], [4.8451, 8.1116, -2.9512, -1.4724, 0.0], [0.74841, 7.2756, 1.1504, -0.5388, 0.0], [5.1213, 8.5565, -3.3917, -1.5474, 0.0], [3.6181, -3.7454, 2.8273, -0.71208, 0.0], [0.040498, 8.5234, 1.4461, -3.9306, 0.0], [-2.6479, 10.1374, -1.331, -5.4707, 0.0], [0.37984, 0.70975, 0.75716, -0.44441, 0.0], [-0.95923, 0.091039, 6.2204, -1.4828, 0.0], [2.8672, 10.0008, -3.2049, -3.1095, 0.0], [1.0182, 9.109, -0.62064, -1.7129, 0.0], [-2.7143, 11.4535, 2.1092, -3.9629, 0.0], [3.8244, -3.1081, 2.4537, 0.52024, 0.0], [2.7961, 2.121, 1.8385, 0.38317, 0.0], [3.5358, 6.7086, -0.81857, 0.47886, 0.0], [-0.7056, 8.7241, 2.2215, -4.5965, 0.0], [4.1542, 7.2756, -2.4766, -1.2099, 0.0], [0.92703, 9.4318, -0.66263, -1.6728, 0.0], [1.8216, -6.4748, 8.0514, -0.41855, 0.0], [-2.4473, 12.6247, 0.73573, -7.6612, 0.0], [3.5862, -3.0957, 2.8093, 0.24481, 0.0], [0.66191, 9.6594, -0.28819, -1.6638, 0.0], [4.7926, 1.7071, -0.051701, 1.4926, 0.0], [4.9852, 8.3516, -2.5425, -1.2823, 0.0], [0.75736, 3.0294, 2.9164, -0.068117, 0.0], [4.6499, 7.6336, -1.9427, -0.37458, 0.0], [-0.023579, 7.1742, 0.78457, -0.75734, 0.0], [0.85574, 0.0082678, 6.6042, -0.53104, 0.0], [0.88298, 0.66009, 6.0096, -0.43277, 0.0], [4.0422, -4.391, 4.7466, 1.137, 0.0], [2.2546, 8.0992, -0.24877, -3.2698, 0.0], [0.38478, 6.5989, -0.3336, -0.56466, 0.0], [3.1541, -5.1711, 6.5991, 0.57455, 0.0], [2.3969, 0.23589, 4.8477, 1.437, 0.0], [4.7114, 2.0755, -0.2702, 1.2379, 0.0], [4.0127, 10.1477, -3.9366, -4.0728, 0.0], [2.6606, 3.1681, 1.9619, 0.18662, 0.0], [3.931, 1.8541, -0.023425, 1.2314, 0.0], [0.01727, 8.693, 1.3989, -3.9668, 0.0], [3.2414, 0.40971, 1.4015, 1.1952, 0.0], [2.2504, 3.5757, 0.35273, 0.2836, 0.0], [-1.3971, 3.3191, -1.3927, -1.9948, 1.0], [0.39012, -0.14279, -0.031994, 0.35084, 1.0], [-1.6677, -7.1535, 7.8929, 0.96765, 1.0], [-3.8483, -12.8047, 15.6824, -1.281, 1.0], [-3.5681, -8.213, 10.083, 0.96765, 1.0], [-2.2804, -0.30626, 1.3347, 1.3763, 1.0], [-1.7582, 2.7397, -2.5323, -2.234, 1.0], [-0.89409, 3.1991, -1.8219, -2.9452, 1.0], [0.3434, 0.12415, -0.28733, 0.14654, 1.0], [-0.9854, -6.661, 5.8245, 0.5461, 1.0], [-2.4115, -9.1359, 9.3444, -0.65259, 1.0], [-1.5252, -6.2534, 5.3524, 0.59912, 1.0], [-0.61442, -0.091058, -0.31818, 0.50214, 1.0], [-0.36506, 2.8928, -3.6461, -3.0603, 1.0], [-5.9034, 6.5679, 0.67661, -6.6797, 1.0], [-1.8215, 2.7521, -0.72261, -2.353, 1.0], [-0.77461, -1.8768, 2.4023, 1.1319, 1.0], [-1.8187, -9.0366, 9.0162, -0.12243, 1.0], [-3.5801, -12.9309, 13.1779, -2.5677, 1.0], [-1.8219, -6.8824, 5.4681, 0.057313, 1.0], [-0.3481, -0.38696, -0.47841, 0.62627, 1.0], [0.47368, 3.3605, -4.5064, -4.0431, 1.0], [-3.4083, 4.8587, -0.76888, -4.8668, 1.0], [-1.6662, -0.30005, 1.4238, 0.024986, 1.0], [-2.0962, -7.1059, 6.6188, -0.33708, 1.0], [-2.6685, -10.4519, 9.1139, -1.7323, 1.0], [-0.47465, -4.3496, 1.9901, 0.7517, 1.0], [1.0552, 1.1857, -2.6411, 0.11033, 1.0], [1.1644, 3.8095, -4.9408, -4.0909, 1.0], [-4.4779, 7.3708, -0.31218, -6.7754, 1.0], [-2.7338, 0.45523, 2.4391, 0.21766, 1.0], [-2.286, -5.4484, 5.8039, 0.88231, 1.0], [-1.6244, -6.3444, 4.6575, 0.16981, 1.0], [0.50813, 0.47799, -1.9804, 0.57714, 1.0], [1.6408, 4.2503, -4.9023, -2.6621, 1.0], [0.81583, 4.84, -5.2613, -6.0823, 1.0], [-5.4901, 9.1048, -0.38758, -5.9763, 1.0], [-3.2238, 2.7935, 0.32274, -0.86078, 1.0], [-2.0631, -1.5147, 1.219, 0.44524, 1.0], [-0.91318, -2.0113, -0.19565, 0.066365, 1.0], [0.6005, 1.9327, -3.2888, -0.32415, 1.0], [0.91315, 3.3377, -4.0557, -1.6741, 1.0], [-0.28015, 3.0729, -3.3857, -2.9155, 1.0], [-3.6085, 3.3253, -0.51954, -3.5737, 1.0], [-6.2003, 8.6806, 0.0091344, -3.703, 1.0], [-4.2932, 3.3419, 0.77258, -0.99785, 1.0], [-3.0265, -0.062088, 0.68604, -0.055186, 1.0], [-1.7015, -0.010356, -0.99337, -0.53104, 1.0], [-0.64326, 2.4748, -2.9452, -1.0276, 1.0], [-0.86339, 1.9348, -2.3729, -1.0897, 1.0], [-2.0659, 1.0512, -0.46298, -1.0974, 1.0], [-2.1333, 1.5685, -0.084261, -1.7453, 1.0], [-1.2568, -1.4733, 2.8718, 0.44653, 1.0], [-3.1128, -6.841, 10.7402, -1.0172, 1.0], [-4.8554, -5.9037, 10.9818, -0.82199, 1.0], [-2.588, 3.8654, -0.3336, -1.2797, 1.0], [0.24394, 1.4733, -1.4192, -0.58535, 1.0], [-1.5322, -5.0966, 6.6779, 0.17498, 1.0], [-4.0025, -13.4979, 17.6772, -3.3202, 1.0], [-4.0173, -8.3123, 12.4547, -1.4375, 1.0], [-3.0731, -0.53181, 2.3877, 0.77627, 1.0], [-1.979, 3.2301, -1.3575, -2.5819, 1.0], [-0.4294, -0.14693, 0.044265, -0.15605, 1.0], [-2.234, -7.0314, 7.4936, 0.61334, 1.0], [-4.211, -12.4736, 14.9704, -1.3884, 1.0], [-3.8073, -8.0971, 10.1772, 0.65084, 1.0], [-2.5912, -0.10554, 1.2798, 1.0414, 1.0], [-2.2482, 3.0915, -2.3969, -2.6711, 1.0], [-1.4427, 3.2922, -1.9702, -3.4392, 1.0], [-0.39416, -0.020702, -0.066267, -0.44699, 1.0], [-1.522, -6.6383, 5.7491, -0.10691, 1.0], [-2.8267, -9.0407, 9.0694, -0.98233, 1.0], [-1.7263, -6.0237, 5.2419, 0.29524, 1.0], [-0.94255, 0.039307, -0.24192, 0.31593, 1.0], [-0.89569, 3.0025, -3.6067, -3.4457, 1.0], [-6.2815, 6.6651, 0.52581, -7.0107, 1.0], [-2.3211, 3.166, -1.0002, -2.7151, 1.0], [-1.3414, -2.0776, 2.8093, 0.60688, 1.0], [-2.258, -9.3263, 9.3727, -0.85949, 1.0], [-3.8858, -12.8461, 12.7957, -3.1353, 1.0], [-1.8969, -6.7893, 5.2761, -0.32544, 1.0], [-0.52645, -0.24832, -0.45613, 0.41938, 1.0], [0.0096613, 3.5612, -4.407, -4.4103, 1.0], [-3.8826, 4.898, -0.92311, -5.0801, 1.0], [-2.1405, -0.16762, 1.321, -0.20906, 1.0], [-2.4824, -7.3046, 6.839, -0.59053, 1.0], [-2.9098, -10.0712, 8.4156, -1.9948, 1.0], [-0.60975, -4.002, 1.8471, 0.6017, 1.0], [0.83625, 1.1071, -2.4706, -0.062945, 1.0], [0.60731, 3.9544, -4.772, -4.4853, 1.0], [-4.8861, 7.0542, -0.17252, -6.959, 1.0], [-3.1366, 0.42212, 2.6225, -0.064238, 1.0], [-2.5754, -5.6574, 6.103, 0.65214, 1.0], [-1.8782, -6.5865, 4.8486, -0.021566, 1.0], [0.24261, 0.57318, -1.9402, 0.44007, 1.0], [1.296, 4.2855, -4.8457, -2.9013, 1.0], [0.25943, 5.0097, -5.0394, -6.3862, 1.0], [-5.873, 9.1752, -0.27448, -6.0422, 1.0], [-3.4605, 2.6901, 0.16165, -1.0224, 1.0], [-2.3797, -1.4402, 1.1273, 0.16076, 1.0], [-1.2424, -1.7175, -0.52553, -0.21036, 1.0], [0.20216, 1.9182, -3.2828, -0.61768, 1.0], [0.59823, 3.5012, -3.9795, -1.7841, 1.0], [-0.77995, 3.2322, -3.282, -3.1004, 1.0], [-4.1409, 3.4619, -0.47841, -3.8879, 1.0], [-6.5084, 8.7696, 0.23191, -3.937, 1.0], [-4.4996, 3.4288, 0.56265, -1.1672, 1.0], [-3.3125, 0.10139, 0.55323, -0.2957, 1.0], [-1.9423, 0.3766, -1.2898, -0.82458, 1.0], [-0.75793, 2.5349, -3.0464, -1.2629, 1.0], [-0.95403, 1.9824, -2.3163, -1.1957, 1.0], [-2.2173, 1.4671, -0.72689, -1.1724, 1.0], [-2.799, 1.9679, -0.42357, -2.1125, 1.0], [-1.8629, -0.84841, 2.5377, 0.097399, 1.0], [-3.5916, -6.2285, 10.2389, -1.1543, 1.0], [-5.1216, -5.3118, 10.3846, -1.0612, 1.0], [-3.2854, 4.0372, -0.45356, -1.8228, 1.0], [-0.56877, 1.4174, -1.4252, -1.1246, 1.0], [-2.3518, -4.8359, 6.6479, -0.060358, 1.0], [-4.4861, -13.2889, 17.3087, -3.2194, 1.0], [-4.3876, -7.7267, 11.9655, -1.4543, 1.0], [-3.3604, -0.32696, 2.1324, 0.6017, 1.0], [-1.0112, 2.9984, -1.1664, -1.6185, 1.0], [0.030219, -1.0512, 1.4024, 0.77369, 1.0], [-1.6514, -8.4985, 9.1122, 1.2379, 1.0], [-3.2692, -12.7406, 15.5573, -0.14182, 1.0], [-2.5701, -6.8452, 8.9999, 2.1353, 1.0], [-1.3066, 0.25244, 0.7623, 1.7758, 1.0], [-1.6637, 3.2881, -2.2701, -2.2224, 1.0], [-0.55008, 2.8659, -1.6488, -2.4319, 1.0], [0.21431, -0.69529, 0.87711, 0.29653, 1.0], [-0.77288, -7.4473, 6.492, 0.36119, 1.0], [-1.8391, -9.0883, 9.2416, -0.10432, 1.0], [-0.63298, -5.1277, 4.5624, 1.4797, 1.0], [0.0040545, 0.62905, -0.64121, 0.75817, 1.0], [-0.28696, 3.1784, -3.5767, -3.1896, 1.0], [-5.2406, 6.6258, -0.19908, -6.8607, 1.0], [-1.4446, 2.1438, -0.47241, -1.6677, 1.0], [-0.65767, -2.8018, 3.7115, 0.99739, 1.0], [-1.5449, -10.1498, 9.6152, -1.2332, 1.0], [-2.8957, -12.0205, 11.9149, -2.7552, 1.0], [-0.81479, -5.7381, 4.3919, 0.3211, 1.0], [0.50225, 0.65388, -1.1793, 0.39998, 1.0], [0.74521, 3.6357, -4.4044, -4.1414, 1.0], [-2.9146, 4.0537, -0.45699, -4.0327, 1.0], [-1.3907, -1.3781, 2.3055, -0.021566, 1.0], [-1.786, -8.1157, 7.0858, -1.2112, 1.0], [-1.7322, -9.2828, 7.719, -1.7168, 1.0], [0.55298, -3.4619, 1.7048, 1.1008, 1.0], [2.031, 1.852, -3.0121, 0.003003, 1.0], [1.2279, 4.0309, -4.6435, -3.9125, 1.0], [-4.2249, 6.2699, 0.15822, -5.5457, 1.0], [-2.5346, -0.77392, 3.3602, 0.00171, 1.0], [-1.749, -6.332, 6.0987, 0.14266, 1.0], [-0.539, -5.167, 3.4399, 0.052141, 1.0], [1.5631, 0.89599, -1.9702, 0.65472, 1.0], [2.3917, 4.5565, -4.9888, -2.8987, 1.0], [0.89512, 4.7738, -4.8431, -5.5909, 1.0], [-5.4808, 8.1819, 0.27818, -5.0323, 1.0], [-2.8833, 1.7713, 0.68946, -0.4638, 1.0], [-1.4174, -2.2535, 1.518, 0.61981, 1.0], [0.4283, -0.94981, -1.0731, 0.3211, 1.0], [1.5904, 2.2121, -3.1183, -0.11725, 1.0], [1.7425, 3.6833, -4.0129, -1.7207, 1.0], [-0.23356, 3.2405, -3.0669, -2.7784, 1.0], [-3.6227, 3.9958, -0.35845, -3.9047, 1.0], [-6.1536, 7.9295, 0.61663, -3.2646, 1.0], [-3.9172, 2.6652, 0.78886, -0.7819, 1.0], [-2.2214, -0.23798, 0.56008, 0.05602, 1.0], [-0.49241, 0.89392, -1.6283, -0.56854, 1.0], [0.26517, 2.4066, -2.8416, -0.59958, 1.0], [-0.10234, 1.8189, -2.2169, -0.56725, 1.0], [-1.6176, 1.0926, -0.35502, -0.59958, 1.0], [-1.8448, 1.254, 0.27218, -1.0728, 1.0], [-1.2786, -2.4087, 4.5735, 0.47627, 1.0], [-2.902, -7.6563, 11.8318, -0.84268, 1.0], [-4.3773, -5.5167, 10.939, -0.4082, 1.0], [-2.0529, 3.8385, -0.79544, -1.2138, 1.0], [0.18868, 0.70148, -0.51182, 0.0055892, 1.0], [-1.7279, -6.841, 8.9494, 0.68058, 1.0], [-3.3793, -13.7731, 17.9274, -2.0323, 1.0], [-3.1273, -7.1121, 11.3897, -0.083634, 1.0], [-2.121, -0.05588, 1.949, 1.353, 1.0], [-1.7697, 3.4329, -1.2144, -2.3789, 1.0], [-0.0012852, 0.13863, -0.19651, 0.0081754, 1.0], [-1.682, -6.8121, 7.1398, 1.3323, 1.0], [-3.4917, -12.1736, 14.3689, -0.61639, 1.0], [-3.1158, -8.6289, 10.4403, 0.97153, 1.0], [-2.0891, -0.48422, 1.704, 1.7435, 1.0], [-1.6936, 2.7852, -2.1835, -1.9276, 1.0], [-1.2846, 3.2715, -1.7671, -3.2608, 1.0], [-0.092194, 0.39315, -0.32846, -0.13794, 1.0], [-1.0292, -6.3879, 5.5255, 0.79955, 1.0], [-2.2083, -9.1069, 8.9991, -0.28406, 1.0], [-1.0744, -6.3113, 5.355, 0.80472, 1.0], [-0.51003, -0.23591, 0.020273, 0.76334, 1.0], [-0.36372, 3.0439, -3.4816, -2.7836, 1.0], [-6.3979, 6.4479, 1.0836, -6.6176, 1.0], [-2.2501, 3.3129, -0.88369, -2.8974, 1.0], [-1.1859, -1.2519, 2.2635, 0.77239, 1.0], [-1.8076, -8.8131, 8.7086, -0.21682, 1.0], [-3.3863, -12.9889, 13.0545, -2.7202, 1.0], [-1.4106, -7.108, 5.6454, 0.31335, 1.0], [-0.21394, -0.68287, 0.096532, 1.1965, 1.0], [0.48797, 3.5674, -4.3882, -3.8116, 1.0], [-3.8167, 5.1401, -0.65063, -5.4306, 1.0], [-1.9555, 0.20692, 1.2473, -0.3707, 1.0], [-2.1786, -6.4479, 6.0344, -0.20777, 1.0], [-2.3299, -9.9532, 8.4756, -1.8733, 1.0], [0.0031201, -4.0061, 1.7956, 0.91722, 1.0], [1.3518, 1.0595, -2.3437, 0.39998, 1.0], [1.2309, 3.8923, -4.8277, -4.0069, 1.0], [-5.0301, 7.5032, -0.13396, -7.5034, 1.0], [-3.0799, 0.60836, 2.7039, -0.23751, 1.0], [-2.2987, -5.227, 5.63, 0.91722, 1.0], [-1.239, -6.541, 4.8151, -0.033204, 1.0], [0.75896, 0.29176, -1.6506, 0.83834, 1.0], [1.6799, 4.2068, -4.5398, -2.3931, 1.0], [0.63655, 5.2022, -5.2159, -6.1211, 1.0], [-6.0598, 9.2952, -0.43642, -6.3694, 1.0], [-3.518, 2.8763, 0.1548, -1.2086, 1.0], [-2.0336, -1.4092, 1.1582, 0.36507, 1.0], [-0.69745, -1.7672, -0.34474, -0.12372, 1.0], [0.75108, 1.9161, -3.1098, -0.20518, 1.0], [0.84546, 3.4826, -3.6307, -1.3961, 1.0], [-0.55648, 3.2136, -3.3085, -2.7965, 1.0], [-3.6817, 3.2239, -0.69347, -3.4004, 1.0], [-6.7526, 8.8172, -0.061983, -3.725, 1.0], [-4.577, 3.4515, 0.66719, -0.94742, 1.0], [-2.9883, 0.31245, 0.45041, 0.068951, 1.0], [-1.4781, 0.14277, -1.1622, -0.48579, 1.0], [-0.46651, 2.3383, -2.9812, -1.0431, 1.0], [-0.8734, 1.6533, -2.1964, -0.78061, 1.0], [-2.1234, 1.1815, -0.55552, -0.81165, 1.0], [-2.3142, 2.0838, -0.46813, -1.6767, 1.0], [-1.4233, -0.98912, 2.3586, 0.39481, 1.0], [-3.0866, -6.6362, 10.5405, -0.89182, 1.0], [-4.7331, -6.1789, 11.388, -1.0741, 1.0], [-2.8829, 3.8964, -0.1888, -1.1672, 1.0], [-0.036127, 1.525, -1.4089, -0.76121, 1.0], [-1.7104, -4.778, 6.2109, 0.3974, 1.0], [-3.8203, -13.0551, 16.9583, -2.3052, 1.0], [-3.7181, -8.5089, 12.363, -0.95518, 1.0], [-2.899, -0.60424, 2.6045, 1.3776, 1.0], [-0.98193, 2.7956, -1.2341, -1.5668, 1.0], [-0.17296, -1.1816, 1.3818, 0.7336, 1.0], [-1.9409, -8.6848, 9.155, 0.94049, 1.0], [-3.5713, -12.4922, 14.8881, -0.47027, 1.0], [-2.9915, -6.6258, 8.6521, 1.8198, 1.0], [-1.8483, 0.31038, 0.77344, 1.4189, 1.0], [-2.2677, 3.2964, -2.2563, -2.4642, 1.0], [-0.50816, 2.868, -1.8108, -2.2612, 1.0], [0.14329, -1.0885, 1.0039, 0.48791, 1.0], [-0.90784, -7.9026, 6.7807, 0.34179, 1.0], [-2.0042, -9.3676, 9.3333, -0.10303, 1.0], [-0.93587, -5.1008, 4.5367, 1.3866, 1.0], [-0.40804, 0.54214, -0.52725, 0.6586, 1.0], [-0.8172, 3.3812, -3.6684, -3.456, 1.0], [-4.8392, 6.6755, -0.24278, -6.5775, 1.0], [-1.2792, 2.1376, -0.47584, -1.3974, 1.0], [-0.66008, -3.226, 3.8058, 1.1836, 1.0], [-1.7713, -10.7665, 10.2184, -1.0043, 1.0], [-3.0061, -12.2377, 11.9552, -2.1603, 1.0], [-1.1022, -5.8395, 4.5641, 0.68705, 1.0], [0.11806, 0.39108, -0.98223, 0.42843, 1.0], [0.11686, 3.735, -4.4379, -4.3741, 1.0], [-2.7264, 3.9213, -0.49212, -3.6371, 1.0], [-1.2369, -1.6906, 2.518, 0.51636, 1.0], [-1.8439, -8.6475, 7.6796, -0.66682, 1.0], [-1.8554, -9.6035, 7.7764, -0.97716, 1.0], [0.16358, -3.3584, 1.3749, 1.3569, 1.0], [1.5077, 1.9596, -3.0584, -0.12243, 1.0], [0.67886, 4.1199, -4.569, -4.1414, 1.0], [-3.9934, 5.8333, 0.54723, -4.9379, 1.0], [-2.3898, -0.78427, 3.0141, 0.76205, 1.0], [-1.7976, -6.7686, 6.6753, 0.89912, 1.0], [-0.70867, -5.5602, 4.0483, 0.903, 1.0], [1.0194, 1.1029, -2.3, 0.59395, 1.0], [1.7875, 4.78, -5.1362, -3.2362, 1.0], [0.27331, 4.8773, -4.9194, -5.8198, 1.0], [-5.1661, 8.0433, 0.044265, -4.4983, 1.0], [-2.7028, 1.6327, 0.83598, -0.091393, 1.0], [-1.4904, -2.2183, 1.6054, 0.89394, 1.0], [-0.014902, -1.0243, -0.94024, 0.64955, 1.0], [0.88992, 2.2638, -3.1046, -0.11855, 1.0], [1.0637, 3.6957, -4.1594, -1.9379, 1.0], [-0.8471, 3.1329, -3.0112, -2.9388, 1.0], [-3.9594, 4.0289, -0.35845, -3.8957, 1.0], [-5.8818, 7.6584, 0.5558, -2.9155, 1.0], [-3.7747, 2.5162, 0.83341, -0.30993, 1.0], [-2.4198, -0.24418, 0.70146, 0.41809, 1.0], [-0.83535, 0.80494, -1.6411, -0.19225, 1.0], [-0.30432, 2.6528, -2.7756, -0.65647, 1.0], [-0.60254, 1.7237, -2.1501, -0.77027, 1.0], [-2.1059, 1.1815, -0.53324, -0.82716, 1.0], [-2.0441, 1.2271, 0.18564, -1.091, 1.0], [-1.5621, -2.2121, 4.2591, 0.27972, 1.0], [-3.2305, -7.2135, 11.6433, -0.94613, 1.0], [-4.8426, -4.9932, 10.4052, -0.53104, 1.0], [-2.3147, 3.6668, -0.6969, -1.2474, 1.0], [-0.11716, 0.60422, -0.38587, -0.059065, 1.0], [-2.0066, -6.719, 9.0162, 0.099985, 1.0], [-3.6961, -13.6779, 17.5795, -2.6181, 1.0], [-3.6012, -6.5389, 10.5234, -0.48967, 1.0], [-2.6286, 0.18002, 1.7956, 0.97282, 1.0], [-0.82601, 2.9611, -1.2864, -1.4647, 1.0], [0.31803, -0.99326, 1.0947, 0.88619, 1.0], [-1.4454, -8.4385, 8.8483, 0.96894, 1.0], [-3.1423, -13.0365, 15.6773, -0.66165, 1.0], [-2.5373, -6.959, 8.8054, 1.5289, 1.0], [-1.366, 0.18416, 0.90539, 1.5806, 1.0], [-1.7064, 3.3088, -2.2829, -2.1978, 1.0], [-0.41965, 2.9094, -1.7859, -2.2069, 1.0], [0.37637, -0.82358, 0.78543, 0.74524, 1.0], [-0.55355, -7.9233, 6.7156, 0.74394, 1.0], [-1.6001, -9.5828, 9.4044, 0.081882, 1.0], [-0.37013, -5.554, 4.7749, 1.547, 1.0], [0.12126, 0.22347, -0.47327, 0.97024, 1.0], [-0.27068, 3.2674, -3.5562, -3.0888, 1.0], [-5.119, 6.6486, -0.049987, -6.5206, 1.0], [-1.3946, 2.3134, -0.44499, -1.4905, 1.0], [-0.69879, -3.3771, 4.1211, 1.5043, 1.0], [-1.48, -10.5244, 9.9176, -0.5026, 1.0], [-2.6649, -12.813, 12.6689, -1.9082, 1.0], [-0.62684, -6.301, 4.7843, 1.106, 1.0], [0.518, 0.25865, -0.84085, 0.96118, 1.0], [0.64376, 3.764, -4.4738, -4.0483, 1.0], [-2.9821, 4.1986, -0.5898, -3.9642, 1.0], [-1.4628, -1.5706, 2.4357, 0.49826, 1.0], [-1.7101, -8.7903, 7.9735, -0.45475, 1.0], [-1.5572, -9.8808, 8.1088, -1.0806, 1.0], [0.74428, -3.7723, 1.6131, 1.5754, 1.0], [2.0177, 1.7982, -2.9581, 0.2099, 1.0], [1.164, 3.913, -4.5544, -3.8672, 1.0], [-4.3667, 6.0692, 0.57208, -5.4668, 1.0], [-2.5919, -1.0553, 3.8949, 0.77757, 1.0], [-1.8046, -6.8141, 6.7019, 1.1681, 1.0], [-0.71868, -5.7154, 3.8298, 1.0233, 1.0], [1.4378, 0.66837, -2.0267, 1.0271, 1.0], [2.1943, 4.5503, -4.976, -2.7254, 1.0], [0.7376, 4.8525, -4.7986, -5.6659, 1.0], [-5.637, 8.1261, 0.13081, -5.0142, 1.0], [-3.0193, 1.7775, 0.73745, -0.45346, 1.0], [-1.6706, -2.09, 1.584, 0.71162, 1.0], [-0.1269, -1.1505, -0.95138, 0.57843, 1.0], [1.2198, 2.0982, -3.1954, 0.12843, 1.0], [1.4501, 3.6067, -4.0557, -1.5966, 1.0], [-0.40857, 3.0977, -2.9607, -2.6892, 1.0], [-3.8952, 3.8157, -0.31304, -3.8194, 1.0], [-6.3679, 8.0102, 0.4247, -3.2207, 1.0], [-4.1429, 2.7749, 0.68261, -0.71984, 1.0], [-2.6864, -0.097265, 0.61663, 0.061192, 1.0], [-1.0555, 0.79459, -1.6968, -0.46768, 1.0], [-0.29858, 2.4769, -2.9512, -0.66165, 1.0], [-0.49948, 1.7734, -2.2469, -0.68104, 1.0], [-1.9881, 0.99945, -0.28562, -0.70044, 1.0], [-1.9389, 1.5706, 0.045979, -1.122, 1.0], [-1.4375, -1.8624, 4.026, 0.55127, 1.0], [-3.1875, -7.5756, 11.8678, -0.57889, 1.0], [-4.6765, -5.6636, 10.969, -0.33449, 1.0], [-2.0285, 3.8468, -0.63435, -1.175, 1.0], [0.26637, 0.73252, -0.67891, 0.03533, 1.0], [-1.7589, -6.4624, 8.4773, 0.31981, 1.0], [-3.5985, -13.6593, 17.6052, -2.4927, 1.0], [-3.3582, -7.2404, 11.4419, -0.57113, 1.0], [-2.3629, -0.10554, 1.9336, 1.1358, 1.0], [-2.1802, 3.3791, -1.2256, -2.6621, 1.0], [-0.40951, -0.15521, 0.060545, -0.088807, 1.0], [-2.2918, -7.257, 7.9597, 0.9211, 1.0], [-4.0214, -12.8006, 15.6199, -0.95647, 1.0], [-3.3884, -8.215, 10.3315, 0.98187, 1.0], [-2.0046, -0.49457, 1.333, 1.6543, 1.0], [-1.7063, 2.7956, -2.378, -2.3491, 1.0], [-1.6386, 3.3584, -1.7302, -3.5646, 1.0], [-0.41645, 0.32487, -0.33617, -0.36036, 1.0], [-1.5877, -6.6072, 5.8022, 0.31593, 1.0], [-2.5961, -9.349, 9.7942, -0.28018, 1.0], [-1.5228, -6.4789, 5.7568, 0.87325, 1.0], [-0.53072, -0.097265, -0.21793, 1.0426, 1.0], [-0.49081, 2.8452, -3.6436, -3.1004, 1.0], [-6.5773, 6.8017, 0.85483, -7.5344, 1.0], [-2.4621, 2.7645, -0.62578, -2.8573, 1.0], [-1.3995, -1.9162, 2.5154, 0.59912, 1.0], [-2.3221, -9.3304, 9.233, -0.79871, 1.0], [-3.73, -12.9723, 12.9817, -2.684, 1.0], [-1.6988, -7.1163, 5.7902, 0.16723, 1.0], [-0.26654, -0.64562, -0.42014, 0.89136, 1.0], [0.33325, 3.3108, -4.5081, -4.012, 1.0], [-4.2091, 4.7283, -0.49126, -5.2159, 1.0], [-2.3142, -0.68494, 1.9833, -0.44829, 1.0], [-2.4835, -7.4494, 6.8964, -0.64484, 1.0], [-2.7611, -10.5099, 9.0239, -1.9547, 1.0], [-0.36025, -4.449, 2.1067, 0.94308, 1.0], [1.0117, 0.9022, -2.3506, 0.42714, 1.0], [0.96708, 3.8426, -4.9314, -4.1323, 1.0], [-5.2049, 7.259, 0.070827, -7.3004, 1.0], [-3.3203, -0.02691, 2.9618, -0.44958, 1.0], [-2.565, -5.7899, 6.0122, 0.046968, 1.0], [-1.5951, -6.572, 4.7689, -0.94354, 1.0], [0.7049, 0.17174, -1.7859, 0.36119, 1.0], [1.7331, 3.9544, -4.7412, -2.5017, 1.0], [0.6818, 4.8504, -5.2133, -6.1043, 1.0], [-6.3364, 9.2848, 0.014275, -6.7844, 1.0], [-3.8053, 2.4273, 0.6809, -1.0871, 1.0], [-2.1979, -2.1252, 1.7151, 0.45171, 1.0], [-0.87874, -2.2121, -0.051701, 0.099985, 1.0], [0.74067, 1.7299, -3.1963, -0.1457, 1.0], [0.98296, 3.4226, -3.9692, -1.7116, 1.0], [-0.3489, 3.1929, -3.4054, -3.1832, 1.0], [-3.8552, 3.5219, -0.38415, -3.8608, 1.0], [-6.9599, 8.9931, 0.2182, -4.572, 1.0], [-4.7462, 3.1205, 1.075, -1.2966, 1.0], [-3.2051, -0.14279, 0.97565, 0.045675, 1.0], [-1.7549, -0.080711, -0.75774, -0.3707, 1.0], [-0.59587, 2.4811, -2.8673, -0.89828, 1.0], [-0.89542, 2.0279, -2.3652, -1.2746, 1.0], [-2.0754, 1.2767, -0.64206, -1.2642, 1.0], [-3.2778, 1.8023, 0.1805, -2.3931, 1.0], [-2.2183, -1.254, 2.9986, 0.36378, 1.0], [-3.5895, -6.572, 10.5251, -0.16381, 1.0], [-5.0477, -5.8023, 11.244, -0.3901, 1.0], [-3.5741, 3.944, -0.07912, -2.1203, 1.0], [-0.7351, 1.7361, -1.4938, -1.1582, 1.0], [-2.2617, -4.7428, 6.3489, 0.11162, 1.0], [-4.244, -13.0634, 17.1116, -2.8017, 1.0], [-4.0218, -8.304, 12.555, -1.5099, 1.0], [-3.0201, -0.67253, 2.7056, 0.85774, 1.0], [-2.4941, 3.5447, -1.3721, -2.8483, 1.0], [-0.83121, 0.039307, 0.05369, -0.23105, 1.0], [-2.5665, -6.8824, 7.5416, 0.70774, 1.0], [-4.4018, -12.9371, 15.6559, -1.6806, 1.0], [-3.7573, -8.2916, 10.3032, 0.38059, 1.0], [-2.4725, -0.40145, 1.4855, 1.1189, 1.0], [-1.9725, 2.8825, -2.3086, -2.3724, 1.0], [-2.0149, 3.6874, -1.9385, -3.8918, 1.0], [-0.82053, 0.65181, -0.48869, -0.52716, 1.0], [-1.7886, -6.3486, 5.6154, 0.42584, 1.0], [-2.9138, -9.4711, 9.7668, -0.60216, 1.0], [-1.8343, -6.5907, 5.6429, 0.54998, 1.0], [-0.8734, -0.033118, -0.20165, 0.55774, 1.0], [-0.70346, 2.957, -3.5947, -3.1457, 1.0], [-6.7387, 6.9879, 0.67833, -7.5887, 1.0], [-2.7723, 3.2777, -0.9351, -3.1457, 1.0], [-1.6641, -1.3678, 1.997, 0.52283, 1.0], [-2.4349, -9.2497, 8.9922, -0.50001, 1.0], [-3.793, -12.7095, 12.7957, -2.825, 1.0], [-1.9551, -6.9756, 5.5383, -0.12889, 1.0], [-0.69078, -0.50077, -0.35417, 0.47498, 1.0], [0.025013, 3.3998, -4.4327, -4.2655, 1.0], [-4.3967, 4.9601, -0.64892, -5.4719, 1.0], [-2.456, -0.24418, 1.4041, -0.45863, 1.0], [-2.62, -6.8555, 6.2169, -0.62285, 1.0], [-2.9662, -10.3257, 8.784, -2.1138, 1.0], [-0.71494, -4.4448, 2.2241, 0.49826, 1.0], [0.6005, 0.99945, -2.2126, 0.097399, 1.0], [0.61652, 3.8944, -4.7275, -4.3948, 1.0], [-5.4414, 7.2363, 0.10938, -7.5642, 1.0], [-3.5798, 0.45937, 2.3457, -0.45734, 1.0], [-2.7769, -5.6967, 5.9179, 0.37671, 1.0], [-1.8356, -6.7562, 5.0585, -0.55044, 1.0], [0.30081, 0.17381, -1.7542, 0.48921, 1.0], [1.3403, 4.1323, -4.7018, -2.5987, 1.0], [0.26877, 4.987, -5.1508, -6.3913, 1.0], [-6.5235, 9.6014, -0.25392, -6.9642, 1.0], [-4.0679, 2.4955, 0.79571, -1.1039, 1.0], [-2.564, -1.7051, 1.5026, 0.32757, 1.0], [-1.3414, -1.9162, -0.15538, -0.11984, 1.0], [0.23874, 2.0879, -3.3522, -0.66553, 1.0], [0.6212, 3.6771, -4.0771, -2.0711, 1.0], [-0.77848, 3.4019, -3.4859, -3.5569, 1.0], [-4.1244, 3.7909, -0.6532, -4.1802, 1.0], [-7.0421, 9.2, 0.25933, -4.6832, 1.0], [-4.9462, 3.5716, 0.82742, -1.4957, 1.0], [-3.5359, 0.30417, 0.6569, -0.2957, 1.0], [-2.0662, 0.16967, -1.0054, -0.82975, 1.0], [-0.88728, 2.808, -3.1432, -1.2035, 1.0], [-1.0941, 2.3072, -2.5237, -1.4453, 1.0], [-2.4458, 1.6285, -0.88541, -1.4802, 1.0], [-3.551, 1.8955, 0.1865, -2.4409, 1.0], [-2.2811, -0.85669, 2.7185, 0.044382, 1.0], [-3.6053, -5.974, 10.0916, -0.82846, 1.0], [-5.0676, -5.1877, 10.4266, -0.86725, 1.0], [-3.9204, 4.0723, -0.23678, -2.1151, 1.0], [-1.1306, 1.8458, -1.3575, -1.3806, 1.0], [-2.4561, -4.5566, 6.4534, -0.056479, 1.0], [-4.4775, -13.0303, 17.0834, -3.0345, 1.0], [-4.1958, -8.1819, 12.1291, -1.6017, 1.0], [-3.38, -0.7077, 2.5325, 0.71808, 1.0], [-2.4365, 3.6026, -1.4166, -2.8948, 1.0], [-0.77688, 0.13036, -0.031137, -0.35389, 1.0], [-2.7083, -6.8266, 7.5339, 0.59007, 1.0], [-4.5531, -12.5854, 15.4417, -1.4983, 1.0], [-3.8894, -7.8322, 9.8208, 0.47498, 1.0], [-2.5084, -0.22763, 1.488, 1.2069, 1.0], [-2.1652, 3.0211, -2.4132, -2.4241, 1.0], [-1.8974, 3.5074, -1.7842, -3.8491, 1.0], [-0.62043, 0.5587, -0.38587, -0.66423, 1.0], [-1.8387, -6.301, 5.6506, 0.19567, 1.0], [-3.0, -9.1566, 9.5766, -0.73018, 1.0], [-1.9116, -6.1603, 5.606, 0.48533, 1.0], [-1.005, 0.084831, -0.2462, 0.45688, 1.0], [-0.87834, 3.257, -3.6778, -3.2944, 1.0], [-6.651, 6.7934, 0.68604, -7.5887, 1.0], [-2.5463, 3.1101, -0.83228, -3.0358, 1.0], [-1.4377, -1.432, 2.1144, 0.42067, 1.0], [-2.4554, -9.0407, 8.862, -0.86983, 1.0], [-3.9411, -12.8792, 13.0597, -3.3125, 1.0], [-2.1241, -6.8969, 5.5992, -0.47156, 1.0], [-0.74324, -0.32902, -0.42785, 0.23317, 1.0], [-0.071503, 3.7412, -4.5415, -4.2526, 1.0], [-4.2333, 4.9166, -0.49212, -5.3207, 1.0], [-2.3675, -0.43663, 1.692, -0.43018, 1.0], [-2.5526, -7.3625, 6.9255, -0.66811, 1.0], [-3.0986, -10.4602, 8.9717, -2.3427, 1.0], [-0.89809, -4.4862, 2.2009, 0.50731, 1.0], [0.56232, 1.0015, -2.2726, -0.0060486, 1.0], [0.53936, 3.8944, -4.8166, -4.3418, 1.0], [-5.3012, 7.3915, 0.029699, -7.3987, 1.0], [-3.3553, 0.35591, 2.6473, -0.37846, 1.0], [-2.7908, -5.7133, 5.953, 0.45946, 1.0], [-1.9983, -6.6072, 4.8254, -0.41984, 1.0], [0.15423, 0.11794, -1.6823, 0.59524, 1.0], [1.208, 4.0744, -4.7635, -2.6129, 1.0], [0.2952, 4.8856, -5.149, -6.2323, 1.0], [-6.4247, 9.5311, 0.022844, -6.8517, 1.0], [-3.9933, 2.6218, 0.62863, -1.1595, 1.0], [-2.659, -1.6058, 1.3647, 0.16464, 1.0], [-1.4094, -2.1252, -0.10397, -0.19225, 1.0], [0.11032, 1.9741, -3.3668, -0.65259, 1.0], [0.52374, 3.644, -4.0746, -1.9909, 1.0], [-0.76794, 3.4598, -3.4405, -3.4276, 1.0], [-3.9698, 3.6812, -0.60008, -4.0133, 1.0], [-7.0364, 9.2931, 0.16594, -4.5396, 1.0], [-4.9447, 3.3005, 1.063, -1.444, 1.0], [-3.5933, 0.22968, 0.7126, -0.3332, 1.0], [-2.1674, 0.12415, -1.0465, -0.86208, 1.0], [-0.9607, 2.6963, -3.1226, -1.3121, 1.0], [-1.0802, 2.1996, -2.5862, -1.2759, 1.0], [-2.3277, 1.4381, -0.82114, -1.2862, 1.0], [-3.7244, 1.9037, -0.035421, -2.5095, 1.0], [-2.5724, -0.95602, 2.7073, -0.16639, 1.0], [-3.9297, -6.0816, 10.0958, -1.0147, 1.0], [-5.2943, -5.1463, 10.3332, -1.1181, 1.0], [-3.8953, 4.0392, -0.3019, -2.1836, 1.0], [-1.2244, 1.7485, -1.4801, -1.4181, 1.0], [-2.6406, -4.4159, 5.983, -0.13924, 1.0], [-4.6338, -12.7509, 16.7166, -3.2168, 1.0], [-4.2887, -7.8633, 11.8387, -1.8978, 1.0], [-3.3458, -0.50491, 2.6328, 0.53705, 1.0], [-1.1188, 3.3357, -1.3455, -1.9573, 1.0], [0.55939, -0.3104, 0.18307, 0.44653, 1.0], [-1.5078, -7.3191, 7.8981, 1.2289, 1.0], [-3.506, -12.5667, 15.1606, -0.75216, 1.0], [-2.9498, -8.273, 10.2646, 1.1629, 1.0], [-1.6029, -0.38903, 1.62, 1.9103, 1.0], [-1.2667, 2.8183, -2.426, -1.8862, 1.0], [-0.49281, 3.0605, -1.8356, -2.834, 1.0], [0.66365, -0.045533, -0.18794, 0.23447, 1.0], [-0.72068, -6.7583, 5.8408, 0.62369, 1.0], [-1.9966, -9.5001, 9.682, -0.12889, 1.0], [-0.97325, -6.4168, 5.6026, 1.0323, 1.0], [-0.025314, -0.17383, -0.11339, 1.2198, 1.0], [0.062525, 2.9301, -3.5467, -2.6737, 1.0], [-5.525, 6.3258, 0.89768, -6.6241, 1.0], [-1.2943, 2.6735, -0.84085, -2.0323, 1.0], [-0.24037, -1.7837, 2.135, 1.2418, 1.0], [-1.3968, -9.6698, 9.4652, -0.34872, 1.0], [-2.9672, -13.2869, 13.4727, -2.6271, 1.0], [-1.1005, -7.2508, 6.0139, 0.36895, 1.0], [0.22432, -0.52147, -0.40386, 1.2017, 1.0], [0.90407, 3.3708, -4.4987, -3.6965, 1.0], [-2.8619, 4.5193, -0.58123, -4.2629, 1.0], [-1.0833, -0.31247, 1.2815, 0.41291, 1.0], [-1.5681, -7.2446, 6.5537, -0.1276, 1.0], [-2.0545, -10.8679, 9.4926, -1.4116, 1.0], [0.2346, -4.5152, 2.1195, 1.4448, 1.0], [1.581, 0.86909, -2.3138, 0.82412, 1.0], [1.5514, 3.8013, -4.9143, -3.7483, 1.0], [-4.1479, 7.1225, -0.083404, -6.4172, 1.0], [-2.2625, -0.099335, 2.8127, 0.48662, 1.0], [-1.7479, -5.823, 5.8699, 1.212, 1.0], [-0.95923, -6.7128, 4.9857, 0.32886, 1.0], [1.3451, 0.23589, -1.8785, 1.3258, 1.0], [2.2279, 4.0951, -4.8037, -2.1112, 1.0], [1.2572, 4.8731, -5.2861, -5.8741, 1.0], [-5.3857, 9.1214, -0.41929, -5.9181, 1.0], [-2.9786, 2.3445, 0.52667, -0.40173, 1.0], [-1.5851, -2.1562, 1.7082, 0.9017, 1.0], [-0.21888, -2.2038, -0.0954, 0.56421, 1.0], [1.3183, 1.9017, -3.3111, 0.065071, 1.0], [1.4896, 3.4288, -4.0309, -1.4259, 1.0], [0.11592, 3.2219, -3.4302, -2.8457, 1.0], [-3.3924, 3.3564, -0.72004, -3.5233, 1.0], [-6.1632, 8.7096, -0.21621, -3.6345, 1.0], [-4.0786, 2.9239, 0.87026, -0.65389, 1.0], [-2.5899, -0.3911, 0.93452, 0.42972, 1.0], [-1.0116, -0.19038, -0.90597, 0.003003, 1.0], [0.066129, 2.4914, -2.9401, -0.62156, 1.0], [-0.24745, 1.9368, -2.4697, -0.80518, 1.0], [-1.5732, 1.0636, -0.71232, -0.8388, 1.0], [-2.1668, 1.5933, 0.045122, -1.678, 1.0], [-1.1667, -1.4237, 2.9241, 0.66119, 1.0], [-2.8391, -6.63, 10.4849, -0.42113, 1.0], [-4.5046, -5.8126, 10.8867, -0.52846, 1.0], [-2.41, 3.7433, -0.40215, -1.2953, 1.0], [0.40614, 1.3492, -1.4501, -0.55949, 1.0], [-1.3887, -4.8773, 6.4774, 0.34179, 1.0], [-3.7503, -13.4586, 17.5932, -2.7771, 1.0], [-3.5637, -8.3827, 12.393, -1.2823, 1.0], [-2.5419, -0.65804, 2.6842, 1.1952, 1.0]]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "no of misses are %d 16\n",
      "accuracy of iteration 0 -----> 98.333333 \n",
      "loss of iteration 0 is 1.666667 \n",
      "\n",
      "no of misses are %d 17\n",
      "accuracy of iteration 1 -----> 98.229167 \n",
      "loss of iteration 1 is 1.770833 \n",
      "\n",
      "no of misses are %d 17\n",
      "accuracy of iteration 2 -----> 98.229167 \n",
      "loss of iteration 2 is 1.770833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 3 -----> 99.479167 \n",
      "loss of iteration 3 is 0.520833 \n",
      "\n",
      "no of misses are %d 11\n",
      "accuracy of iteration 4 -----> 98.854167 \n",
      "loss of iteration 4 is 1.145833 \n",
      "\n",
      "no of misses are %d 13\n",
      "accuracy of iteration 5 -----> 98.645833 \n",
      "loss of iteration 5 is 1.354167 \n",
      "\n",
      "no of misses are %d 12\n",
      "accuracy of iteration 6 -----> 98.750000 \n",
      "loss of iteration 6 is 1.250000 \n",
      "\n",
      "no of misses are %d 11\n",
      "accuracy of iteration 7 -----> 98.854167 \n",
      "loss of iteration 7 is 1.145833 \n",
      "\n",
      "no of misses are %d 10\n",
      "accuracy of iteration 8 -----> 98.958333 \n",
      "loss of iteration 8 is 1.041667 \n",
      "\n",
      "no of misses are %d 12\n",
      "accuracy of iteration 9 -----> 98.750000 \n",
      "loss of iteration 9 is 1.250000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 10 -----> 99.375000 \n",
      "loss of iteration 10 is 0.625000 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 11 -----> 99.166667 \n",
      "loss of iteration 11 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 12 -----> 99.479167 \n",
      "loss of iteration 12 is 0.520833 \n",
      "\n",
      "no of misses are %d 10\n",
      "accuracy of iteration 13 -----> 98.958333 \n",
      "loss of iteration 13 is 1.041667 \n",
      "\n",
      "no of misses are %d 10\n",
      "accuracy of iteration 14 -----> 98.958333 \n",
      "loss of iteration 14 is 1.041667 \n",
      "\n",
      "no of misses are %d 11\n",
      "accuracy of iteration 15 -----> 98.854167 \n",
      "loss of iteration 15 is 1.145833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 16 -----> 99.270833 \n",
      "loss of iteration 16 is 0.729167 \n",
      "\n",
      "no of misses are %d 12\n",
      "accuracy of iteration 17 -----> 98.750000 \n",
      "loss of iteration 17 is 1.250000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 18 -----> 99.375000 \n",
      "loss of iteration 18 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 19 -----> 99.479167 \n",
      "loss of iteration 19 is 0.520833 \n",
      "\n",
      "no of misses are %d 10\n",
      "accuracy of iteration 20 -----> 98.958333 \n",
      "loss of iteration 20 is 1.041667 \n",
      "\n",
      "no of misses are %d 14\n",
      "accuracy of iteration 21 -----> 98.541667 \n",
      "loss of iteration 21 is 1.458333 \n",
      "\n",
      "no of misses are %d 12\n",
      "accuracy of iteration 22 -----> 98.750000 \n",
      "loss of iteration 22 is 1.250000 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 23 -----> 99.270833 \n",
      "loss of iteration 23 is 0.729167 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 24 -----> 99.270833 \n",
      "loss of iteration 24 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 25 -----> 99.479167 \n",
      "loss of iteration 25 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 26 -----> 99.479167 \n",
      "loss of iteration 26 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 27 -----> 99.375000 \n",
      "loss of iteration 27 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 28 -----> 99.479167 \n",
      "loss of iteration 28 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 29 -----> 99.479167 \n",
      "loss of iteration 29 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 30 -----> 99.375000 \n",
      "loss of iteration 30 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 31 -----> 99.479167 \n",
      "loss of iteration 31 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 32 -----> 99.375000 \n",
      "loss of iteration 32 is 0.625000 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 33 -----> 99.166667 \n",
      "loss of iteration 33 is 0.833333 \n",
      "\n",
      "no of misses are %d 13\n",
      "accuracy of iteration 34 -----> 98.645833 \n",
      "loss of iteration 34 is 1.354167 \n",
      "\n",
      "no of misses are %d 9\n",
      "accuracy of iteration 35 -----> 99.062500 \n",
      "loss of iteration 35 is 0.937500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 36 -----> 99.583333 \n",
      "loss of iteration 36 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 37 -----> 99.479167 \n",
      "loss of iteration 37 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 38 -----> 99.166667 \n",
      "loss of iteration 38 is 0.833333 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 39 -----> 99.166667 \n",
      "loss of iteration 39 is 0.833333 \n",
      "\n",
      "no of misses are %d 13\n",
      "accuracy of iteration 40 -----> 98.645833 \n",
      "loss of iteration 40 is 1.354167 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 41 -----> 99.270833 \n",
      "loss of iteration 41 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 42 -----> 99.687500 \n",
      "loss of iteration 42 is 0.312500 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 43 -----> 99.166667 \n",
      "loss of iteration 43 is 0.833333 \n",
      "\n",
      "no of misses are %d 9\n",
      "accuracy of iteration 44 -----> 99.062500 \n",
      "loss of iteration 44 is 0.937500 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 45 -----> 99.166667 \n",
      "loss of iteration 45 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 46 -----> 99.479167 \n",
      "loss of iteration 46 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 47 -----> 99.166667 \n",
      "loss of iteration 47 is 0.833333 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 48 -----> 99.270833 \n",
      "loss of iteration 48 is 0.729167 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 49 -----> 99.166667 \n",
      "loss of iteration 49 is 0.833333 \n",
      "\n",
      "no of misses are %d 12\n",
      "accuracy of iteration 50 -----> 98.750000 \n",
      "loss of iteration 50 is 1.250000 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 51 -----> 99.687500 \n",
      "loss of iteration 51 is 0.312500 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 52 -----> 99.166667 \n",
      "loss of iteration 52 is 0.833333 \n",
      "\n",
      "no of misses are %d 10\n",
      "accuracy of iteration 53 -----> 98.958333 \n",
      "loss of iteration 53 is 1.041667 \n",
      "\n",
      "no of misses are %d 10\n",
      "accuracy of iteration 54 -----> 98.958333 \n",
      "loss of iteration 54 is 1.041667 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 55 -----> 99.166667 \n",
      "loss of iteration 55 is 0.833333 \n",
      "\n",
      "no of misses are %d 10\n",
      "accuracy of iteration 56 -----> 98.958333 \n",
      "loss of iteration 56 is 1.041667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 57 -----> 99.479167 \n",
      "loss of iteration 57 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 58 -----> 99.166667 \n",
      "loss of iteration 58 is 0.833333 \n",
      "\n",
      "no of misses are %d 10\n",
      "accuracy of iteration 59 -----> 98.958333 \n",
      "loss of iteration 59 is 1.041667 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 60 -----> 99.687500 \n",
      "loss of iteration 60 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 61 -----> 99.479167 \n",
      "loss of iteration 61 is 0.520833 \n",
      "\n",
      "no of misses are %d 11\n",
      "accuracy of iteration 62 -----> 98.854167 \n",
      "loss of iteration 62 is 1.145833 \n",
      "\n",
      "no of misses are %d 9\n",
      "accuracy of iteration 63 -----> 99.062500 \n",
      "loss of iteration 63 is 0.937500 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 64 -----> 99.166667 \n",
      "loss of iteration 64 is 0.833333 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 65 -----> 99.166667 \n",
      "loss of iteration 65 is 0.833333 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 66 -----> 99.687500 \n",
      "loss of iteration 66 is 0.312500 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 67 -----> 99.166667 \n",
      "loss of iteration 67 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 68 -----> 99.479167 \n",
      "loss of iteration 68 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 69 -----> 99.166667 \n",
      "loss of iteration 69 is 0.833333 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 70 -----> 99.583333 \n",
      "loss of iteration 70 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 71 -----> 99.375000 \n",
      "loss of iteration 71 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 72 -----> 99.479167 \n",
      "loss of iteration 72 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 73 -----> 99.375000 \n",
      "loss of iteration 73 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 74 -----> 99.583333 \n",
      "loss of iteration 74 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 75 -----> 99.479167 \n",
      "loss of iteration 75 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 76 -----> 99.479167 \n",
      "loss of iteration 76 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 77 -----> 99.375000 \n",
      "loss of iteration 77 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 78 -----> 99.479167 \n",
      "loss of iteration 78 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 79 -----> 99.479167 \n",
      "loss of iteration 79 is 0.520833 \n",
      "\n",
      "no of misses are %d 9\n",
      "accuracy of iteration 80 -----> 99.062500 \n",
      "loss of iteration 80 is 0.937500 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 81 -----> 99.166667 \n",
      "loss of iteration 81 is 0.833333 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 82 -----> 99.687500 \n",
      "loss of iteration 82 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 83 -----> 99.479167 \n",
      "loss of iteration 83 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 84 -----> 99.166667 \n",
      "loss of iteration 84 is 0.833333 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 85 -----> 99.270833 \n",
      "loss of iteration 85 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 86 -----> 99.479167 \n",
      "loss of iteration 86 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 87 -----> 99.479167 \n",
      "loss of iteration 87 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 88 -----> 99.375000 \n",
      "loss of iteration 88 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 89 -----> 99.479167 \n",
      "loss of iteration 89 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 90 -----> 99.479167 \n",
      "loss of iteration 90 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 91 -----> 99.583333 \n",
      "loss of iteration 91 is 0.416667 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 92 -----> 99.583333 \n",
      "loss of iteration 92 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 93 -----> 99.479167 \n",
      "loss of iteration 93 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 94 -----> 99.479167 \n",
      "loss of iteration 94 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 95 -----> 99.687500 \n",
      "loss of iteration 95 is 0.312500 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 96 -----> 99.270833 \n",
      "loss of iteration 96 is 0.729167 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 97 -----> 99.270833 \n",
      "loss of iteration 97 is 0.729167 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 98 -----> 99.166667 \n",
      "loss of iteration 98 is 0.833333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 99 -----> 99.375000 \n",
      "loss of iteration 99 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 100 -----> 99.479167 \n",
      "loss of iteration 100 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 101 -----> 99.479167 \n",
      "loss of iteration 101 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 102 -----> 99.687500 \n",
      "loss of iteration 102 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 103 -----> 99.479167 \n",
      "loss of iteration 103 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 104 -----> 99.375000 \n",
      "loss of iteration 104 is 0.625000 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 105 -----> 99.166667 \n",
      "loss of iteration 105 is 0.833333 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 106 -----> 99.166667 \n",
      "loss of iteration 106 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 107 -----> 99.479167 \n",
      "loss of iteration 107 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 108 -----> 99.583333 \n",
      "loss of iteration 108 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 109 -----> 99.375000 \n",
      "loss of iteration 109 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 110 -----> 99.479167 \n",
      "loss of iteration 110 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 111 -----> 99.479167 \n",
      "loss of iteration 111 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 112 -----> 99.687500 \n",
      "loss of iteration 112 is 0.312500 \n",
      "\n",
      "no of misses are %d 9\n",
      "accuracy of iteration 113 -----> 99.062500 \n",
      "loss of iteration 113 is 0.937500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 114 -----> 99.479167 \n",
      "loss of iteration 114 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 115 -----> 99.583333 \n",
      "loss of iteration 115 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 116 -----> 99.479167 \n",
      "loss of iteration 116 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 117 -----> 99.375000 \n",
      "loss of iteration 117 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 118 -----> 99.479167 \n",
      "loss of iteration 118 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 119 -----> 99.479167 \n",
      "loss of iteration 119 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 120 -----> 99.687500 \n",
      "loss of iteration 120 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 121 -----> 99.479167 \n",
      "loss of iteration 121 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 122 -----> 99.479167 \n",
      "loss of iteration 122 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 123 -----> 99.583333 \n",
      "loss of iteration 123 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 124 -----> 99.375000 \n",
      "loss of iteration 124 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 125 -----> 99.479167 \n",
      "loss of iteration 125 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 126 -----> 99.479167 \n",
      "loss of iteration 126 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 127 -----> 99.687500 \n",
      "loss of iteration 127 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 128 -----> 99.479167 \n",
      "loss of iteration 128 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 129 -----> 99.687500 \n",
      "loss of iteration 129 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 130 -----> 99.479167 \n",
      "loss of iteration 130 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 131 -----> 99.583333 \n",
      "loss of iteration 131 is 0.416667 \n",
      "\n",
      "no of misses are %d 9\n",
      "accuracy of iteration 132 -----> 99.062500 \n",
      "loss of iteration 132 is 0.937500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 133 -----> 99.479167 \n",
      "loss of iteration 133 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 134 -----> 99.687500 \n",
      "loss of iteration 134 is 0.312500 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 135 -----> 99.270833 \n",
      "loss of iteration 135 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 136 -----> 99.479167 \n",
      "loss of iteration 136 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 137 -----> 99.583333 \n",
      "loss of iteration 137 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 138 -----> 99.479167 \n",
      "loss of iteration 138 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 139 -----> 99.479167 \n",
      "loss of iteration 139 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 140 -----> 99.583333 \n",
      "loss of iteration 140 is 0.416667 \n",
      "\n",
      "no of misses are %d 9\n",
      "accuracy of iteration 141 -----> 99.062500 \n",
      "loss of iteration 141 is 0.937500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 142 -----> 99.479167 \n",
      "loss of iteration 142 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 143 -----> 99.270833 \n",
      "loss of iteration 143 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 144 -----> 99.479167 \n",
      "loss of iteration 144 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 145 -----> 99.375000 \n",
      "loss of iteration 145 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 146 -----> 99.479167 \n",
      "loss of iteration 146 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 147 -----> 99.479167 \n",
      "loss of iteration 147 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 148 -----> 99.479167 \n",
      "loss of iteration 148 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 149 -----> 99.583333 \n",
      "loss of iteration 149 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 150 -----> 99.479167 \n",
      "loss of iteration 150 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 151 -----> 99.479167 \n",
      "loss of iteration 151 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 152 -----> 99.583333 \n",
      "loss of iteration 152 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 153 -----> 99.375000 \n",
      "loss of iteration 153 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 154 -----> 99.375000 \n",
      "loss of iteration 154 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 155 -----> 99.479167 \n",
      "loss of iteration 155 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 156 -----> 99.479167 \n",
      "loss of iteration 156 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 157 -----> 99.375000 \n",
      "loss of iteration 157 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 158 -----> 99.479167 \n",
      "loss of iteration 158 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 159 -----> 99.687500 \n",
      "loss of iteration 159 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 160 -----> 99.479167 \n",
      "loss of iteration 160 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 161 -----> 99.270833 \n",
      "loss of iteration 161 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 162 -----> 99.479167 \n",
      "loss of iteration 162 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 163 -----> 99.375000 \n",
      "loss of iteration 163 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 164 -----> 99.479167 \n",
      "loss of iteration 164 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 165 -----> 99.687500 \n",
      "loss of iteration 165 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 166 -----> 99.583333 \n",
      "loss of iteration 166 is 0.416667 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 167 -----> 99.270833 \n",
      "loss of iteration 167 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 168 -----> 99.479167 \n",
      "loss of iteration 168 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 169 -----> 99.583333 \n",
      "loss of iteration 169 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 170 -----> 99.375000 \n",
      "loss of iteration 170 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 171 -----> 99.479167 \n",
      "loss of iteration 171 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 172 -----> 99.479167 \n",
      "loss of iteration 172 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 173 -----> 99.375000 \n",
      "loss of iteration 173 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 174 -----> 99.479167 \n",
      "loss of iteration 174 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 175 -----> 99.687500 \n",
      "loss of iteration 175 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 176 -----> 99.479167 \n",
      "loss of iteration 176 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 177 -----> 99.687500 \n",
      "loss of iteration 177 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 178 -----> 99.479167 \n",
      "loss of iteration 178 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 179 -----> 99.583333 \n",
      "loss of iteration 179 is 0.416667 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 180 -----> 99.270833 \n",
      "loss of iteration 180 is 0.729167 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 181 -----> 99.375000 \n",
      "loss of iteration 181 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 182 -----> 99.583333 \n",
      "loss of iteration 182 is 0.416667 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 183 -----> 99.270833 \n",
      "loss of iteration 183 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 184 -----> 99.479167 \n",
      "loss of iteration 184 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 185 -----> 99.375000 \n",
      "loss of iteration 185 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 186 -----> 99.479167 \n",
      "loss of iteration 186 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 187 -----> 99.583333 \n",
      "loss of iteration 187 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 188 -----> 99.479167 \n",
      "loss of iteration 188 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 189 -----> 99.583333 \n",
      "loss of iteration 189 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 190 -----> 99.479167 \n",
      "loss of iteration 190 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 191 -----> 99.270833 \n",
      "loss of iteration 191 is 0.729167 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 192 -----> 99.375000 \n",
      "loss of iteration 192 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 193 -----> 99.479167 \n",
      "loss of iteration 193 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 194 -----> 99.479167 \n",
      "loss of iteration 194 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 195 -----> 99.375000 \n",
      "loss of iteration 195 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 196 -----> 99.479167 \n",
      "loss of iteration 196 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 197 -----> 99.687500 \n",
      "loss of iteration 197 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 198 -----> 99.479167 \n",
      "loss of iteration 198 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 199 -----> 99.270833 \n",
      "loss of iteration 199 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 200 -----> 99.479167 \n",
      "loss of iteration 200 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 201 -----> 99.375000 \n",
      "loss of iteration 201 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 202 -----> 99.479167 \n",
      "loss of iteration 202 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 203 -----> 99.687500 \n",
      "loss of iteration 203 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 204 -----> 99.583333 \n",
      "loss of iteration 204 is 0.416667 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 205 -----> 99.687500 \n",
      "loss of iteration 205 is 0.312500 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 206 -----> 99.375000 \n",
      "loss of iteration 206 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 207 -----> 99.479167 \n",
      "loss of iteration 207 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 208 -----> 99.375000 \n",
      "loss of iteration 208 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 209 -----> 99.479167 \n",
      "loss of iteration 209 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 210 -----> 99.479167 \n",
      "loss of iteration 210 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 211 -----> 99.375000 \n",
      "loss of iteration 211 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 212 -----> 99.479167 \n",
      "loss of iteration 212 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 213 -----> 99.687500 \n",
      "loss of iteration 213 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 214 -----> 99.479167 \n",
      "loss of iteration 214 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 215 -----> 99.270833 \n",
      "loss of iteration 215 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 216 -----> 99.479167 \n",
      "loss of iteration 216 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 217 -----> 99.479167 \n",
      "loss of iteration 217 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 218 -----> 99.375000 \n",
      "loss of iteration 218 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 219 -----> 99.583333 \n",
      "loss of iteration 219 is 0.416667 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 220 -----> 99.270833 \n",
      "loss of iteration 220 is 0.729167 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 221 -----> 99.583333 \n",
      "loss of iteration 221 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 222 -----> 99.375000 \n",
      "loss of iteration 222 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 223 -----> 99.583333 \n",
      "loss of iteration 223 is 0.416667 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 224 -----> 99.583333 \n",
      "loss of iteration 224 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 225 -----> 99.375000 \n",
      "loss of iteration 225 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 226 -----> 99.479167 \n",
      "loss of iteration 226 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 227 -----> 99.479167 \n",
      "loss of iteration 227 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 228 -----> 99.166667 \n",
      "loss of iteration 228 is 0.833333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 229 -----> 99.375000 \n",
      "loss of iteration 229 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 230 -----> 99.583333 \n",
      "loss of iteration 230 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 231 -----> 99.479167 \n",
      "loss of iteration 231 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 232 -----> 99.479167 \n",
      "loss of iteration 232 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 233 -----> 99.479167 \n",
      "loss of iteration 233 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 234 -----> 99.583333 \n",
      "loss of iteration 234 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 235 -----> 99.375000 \n",
      "loss of iteration 235 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 236 -----> 99.479167 \n",
      "loss of iteration 236 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 237 -----> 99.583333 \n",
      "loss of iteration 237 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 238 -----> 99.479167 \n",
      "loss of iteration 238 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 239 -----> 99.375000 \n",
      "loss of iteration 239 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 240 -----> 99.479167 \n",
      "loss of iteration 240 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 241 -----> 99.479167 \n",
      "loss of iteration 241 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 242 -----> 99.687500 \n",
      "loss of iteration 242 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 243 -----> 99.479167 \n",
      "loss of iteration 243 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 244 -----> 99.479167 \n",
      "loss of iteration 244 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 245 -----> 99.583333 \n",
      "loss of iteration 245 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 246 -----> 99.479167 \n",
      "loss of iteration 246 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 247 -----> 99.583333 \n",
      "loss of iteration 247 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 248 -----> 99.479167 \n",
      "loss of iteration 248 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 249 -----> 99.375000 \n",
      "loss of iteration 249 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 250 -----> 99.479167 \n",
      "loss of iteration 250 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 251 -----> 99.479167 \n",
      "loss of iteration 251 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 252 -----> 99.687500 \n",
      "loss of iteration 252 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 253 -----> 99.479167 \n",
      "loss of iteration 253 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 254 -----> 99.479167 \n",
      "loss of iteration 254 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 255 -----> 99.583333 \n",
      "loss of iteration 255 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 256 -----> 99.479167 \n",
      "loss of iteration 256 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 257 -----> 99.583333 \n",
      "loss of iteration 257 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 258 -----> 99.479167 \n",
      "loss of iteration 258 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 259 -----> 99.375000 \n",
      "loss of iteration 259 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 260 -----> 99.479167 \n",
      "loss of iteration 260 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 261 -----> 99.375000 \n",
      "loss of iteration 261 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 262 -----> 99.479167 \n",
      "loss of iteration 262 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 263 -----> 99.479167 \n",
      "loss of iteration 263 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 264 -----> 99.687500 \n",
      "loss of iteration 264 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 265 -----> 99.479167 \n",
      "loss of iteration 265 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 266 -----> 99.687500 \n",
      "loss of iteration 266 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 267 -----> 99.479167 \n",
      "loss of iteration 267 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 268 -----> 99.583333 \n",
      "loss of iteration 268 is 0.416667 \n",
      "\n",
      "no of misses are %d 9\n",
      "accuracy of iteration 269 -----> 99.062500 \n",
      "loss of iteration 269 is 0.937500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 270 -----> 99.479167 \n",
      "loss of iteration 270 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 271 -----> 99.375000 \n",
      "loss of iteration 271 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 272 -----> 99.479167 \n",
      "loss of iteration 272 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 273 -----> 99.375000 \n",
      "loss of iteration 273 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 274 -----> 99.479167 \n",
      "loss of iteration 274 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 275 -----> 99.687500 \n",
      "loss of iteration 275 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 276 -----> 99.583333 \n",
      "loss of iteration 276 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 277 -----> 99.375000 \n",
      "loss of iteration 277 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 278 -----> 99.479167 \n",
      "loss of iteration 278 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 279 -----> 99.583333 \n",
      "loss of iteration 279 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 280 -----> 99.375000 \n",
      "loss of iteration 280 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 281 -----> 99.479167 \n",
      "loss of iteration 281 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 282 -----> 99.479167 \n",
      "loss of iteration 282 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 283 -----> 99.583333 \n",
      "loss of iteration 283 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 284 -----> 99.375000 \n",
      "loss of iteration 284 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 285 -----> 99.375000 \n",
      "loss of iteration 285 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 286 -----> 99.479167 \n",
      "loss of iteration 286 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 287 -----> 99.479167 \n",
      "loss of iteration 287 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 288 -----> 99.479167 \n",
      "loss of iteration 288 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 289 -----> 99.583333 \n",
      "loss of iteration 289 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 290 -----> 99.479167 \n",
      "loss of iteration 290 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 291 -----> 99.687500 \n",
      "loss of iteration 291 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 292 -----> 99.479167 \n",
      "loss of iteration 292 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 293 -----> 99.479167 \n",
      "loss of iteration 293 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 294 -----> 99.583333 \n",
      "loss of iteration 294 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 295 -----> 99.479167 \n",
      "loss of iteration 295 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 296 -----> 99.583333 \n",
      "loss of iteration 296 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 297 -----> 99.479167 \n",
      "loss of iteration 297 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 298 -----> 99.375000 \n",
      "loss of iteration 298 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 299 -----> 99.479167 \n",
      "loss of iteration 299 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 300 -----> 99.375000 \n",
      "loss of iteration 300 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 301 -----> 99.479167 \n",
      "loss of iteration 301 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 302 -----> 99.479167 \n",
      "loss of iteration 302 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 303 -----> 99.583333 \n",
      "loss of iteration 303 is 0.416667 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 304 -----> 99.270833 \n",
      "loss of iteration 304 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 305 -----> 99.479167 \n",
      "loss of iteration 305 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 306 -----> 99.583333 \n",
      "loss of iteration 306 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 307 -----> 99.479167 \n",
      "loss of iteration 307 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 308 -----> 99.375000 \n",
      "loss of iteration 308 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 309 -----> 99.479167 \n",
      "loss of iteration 309 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 310 -----> 99.270833 \n",
      "loss of iteration 310 is 0.729167 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 311 -----> 99.270833 \n",
      "loss of iteration 311 is 0.729167 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 312 -----> 99.166667 \n",
      "loss of iteration 312 is 0.833333 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 313 -----> 99.687500 \n",
      "loss of iteration 313 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 314 -----> 99.583333 \n",
      "loss of iteration 314 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 315 -----> 99.479167 \n",
      "loss of iteration 315 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 316 -----> 99.687500 \n",
      "loss of iteration 316 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 317 -----> 99.479167 \n",
      "loss of iteration 317 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 318 -----> 99.270833 \n",
      "loss of iteration 318 is 0.729167 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 319 -----> 99.583333 \n",
      "loss of iteration 319 is 0.416667 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 320 -----> 99.270833 \n",
      "loss of iteration 320 is 0.729167 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 321 -----> 99.583333 \n",
      "loss of iteration 321 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 322 -----> 99.479167 \n",
      "loss of iteration 322 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 323 -----> 99.583333 \n",
      "loss of iteration 323 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 324 -----> 99.479167 \n",
      "loss of iteration 324 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 325 -----> 99.270833 \n",
      "loss of iteration 325 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 326 -----> 99.687500 \n",
      "loss of iteration 326 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 327 -----> 99.479167 \n",
      "loss of iteration 327 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 328 -----> 99.166667 \n",
      "loss of iteration 328 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 329 -----> 99.479167 \n",
      "loss of iteration 329 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 330 -----> 99.583333 \n",
      "loss of iteration 330 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 331 -----> 99.479167 \n",
      "loss of iteration 331 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 332 -----> 99.375000 \n",
      "loss of iteration 332 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 333 -----> 99.479167 \n",
      "loss of iteration 333 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 334 -----> 99.583333 \n",
      "loss of iteration 334 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 335 -----> 99.479167 \n",
      "loss of iteration 335 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 336 -----> 99.583333 \n",
      "loss of iteration 336 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 337 -----> 99.479167 \n",
      "loss of iteration 337 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 338 -----> 99.375000 \n",
      "loss of iteration 338 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 339 -----> 99.375000 \n",
      "loss of iteration 339 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 340 -----> 99.479167 \n",
      "loss of iteration 340 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 341 -----> 99.479167 \n",
      "loss of iteration 341 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 342 -----> 99.687500 \n",
      "loss of iteration 342 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 343 -----> 99.479167 \n",
      "loss of iteration 343 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 344 -----> 99.270833 \n",
      "loss of iteration 344 is 0.729167 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 345 -----> 99.583333 \n",
      "loss of iteration 345 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 346 -----> 99.375000 \n",
      "loss of iteration 346 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 347 -----> 99.791667 \n",
      "loss of iteration 347 is 0.208333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 348 -----> 99.479167 \n",
      "loss of iteration 348 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 349 -----> 99.479167 \n",
      "loss of iteration 349 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 350 -----> 99.166667 \n",
      "loss of iteration 350 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 351 -----> 99.479167 \n",
      "loss of iteration 351 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 352 -----> 99.583333 \n",
      "loss of iteration 352 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 353 -----> 99.479167 \n",
      "loss of iteration 353 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 354 -----> 99.479167 \n",
      "loss of iteration 354 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 355 -----> 99.479167 \n",
      "loss of iteration 355 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 356 -----> 99.583333 \n",
      "loss of iteration 356 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 357 -----> 99.375000 \n",
      "loss of iteration 357 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 358 -----> 99.375000 \n",
      "loss of iteration 358 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 359 -----> 99.479167 \n",
      "loss of iteration 359 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 360 -----> 99.479167 \n",
      "loss of iteration 360 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 361 -----> 99.687500 \n",
      "loss of iteration 361 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 362 -----> 99.479167 \n",
      "loss of iteration 362 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 363 -----> 99.270833 \n",
      "loss of iteration 363 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 364 -----> 99.687500 \n",
      "loss of iteration 364 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 365 -----> 99.479167 \n",
      "loss of iteration 365 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 366 -----> 99.270833 \n",
      "loss of iteration 366 is 0.729167 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 367 -----> 99.583333 \n",
      "loss of iteration 367 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 368 -----> 99.375000 \n",
      "loss of iteration 368 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 369 -----> 99.791667 \n",
      "loss of iteration 369 is 0.208333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 370 -----> 99.479167 \n",
      "loss of iteration 370 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 371 -----> 99.479167 \n",
      "loss of iteration 371 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 372 -----> 99.166667 \n",
      "loss of iteration 372 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 373 -----> 99.479167 \n",
      "loss of iteration 373 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 374 -----> 99.583333 \n",
      "loss of iteration 374 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 375 -----> 99.479167 \n",
      "loss of iteration 375 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 376 -----> 99.479167 \n",
      "loss of iteration 376 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 377 -----> 99.270833 \n",
      "loss of iteration 377 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 378 -----> 99.687500 \n",
      "loss of iteration 378 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 379 -----> 99.479167 \n",
      "loss of iteration 379 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 380 -----> 99.166667 \n",
      "loss of iteration 380 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 381 -----> 99.479167 \n",
      "loss of iteration 381 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 382 -----> 99.583333 \n",
      "loss of iteration 382 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 383 -----> 99.479167 \n",
      "loss of iteration 383 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 384 -----> 99.479167 \n",
      "loss of iteration 384 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 385 -----> 99.583333 \n",
      "loss of iteration 385 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 386 -----> 99.479167 \n",
      "loss of iteration 386 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 387 -----> 99.375000 \n",
      "loss of iteration 387 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 388 -----> 99.375000 \n",
      "loss of iteration 388 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 389 -----> 99.791667 \n",
      "loss of iteration 389 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 390 -----> 99.375000 \n",
      "loss of iteration 390 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 391 -----> 99.479167 \n",
      "loss of iteration 391 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 392 -----> 99.479167 \n",
      "loss of iteration 392 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 393 -----> 99.479167 \n",
      "loss of iteration 393 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 394 -----> 99.166667 \n",
      "loss of iteration 394 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 395 -----> 99.479167 \n",
      "loss of iteration 395 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 396 -----> 99.583333 \n",
      "loss of iteration 396 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 397 -----> 99.479167 \n",
      "loss of iteration 397 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 398 -----> 99.375000 \n",
      "loss of iteration 398 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 399 -----> 99.479167 \n",
      "loss of iteration 399 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 400 -----> 99.687500 \n",
      "loss of iteration 400 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 401 -----> 99.583333 \n",
      "loss of iteration 401 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 402 -----> 99.375000 \n",
      "loss of iteration 402 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 403 -----> 99.583333 \n",
      "loss of iteration 403 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 404 -----> 99.479167 \n",
      "loss of iteration 404 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 405 -----> 99.479167 \n",
      "loss of iteration 405 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 406 -----> 99.479167 \n",
      "loss of iteration 406 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 407 -----> 99.479167 \n",
      "loss of iteration 407 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 408 -----> 99.583333 \n",
      "loss of iteration 408 is 0.416667 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 409 -----> 99.270833 \n",
      "loss of iteration 409 is 0.729167 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 410 -----> 99.583333 \n",
      "loss of iteration 410 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 411 -----> 99.375000 \n",
      "loss of iteration 411 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 412 -----> 99.583333 \n",
      "loss of iteration 412 is 0.416667 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 413 -----> 99.583333 \n",
      "loss of iteration 413 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 414 -----> 99.375000 \n",
      "loss of iteration 414 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 415 -----> 99.479167 \n",
      "loss of iteration 415 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 416 -----> 99.479167 \n",
      "loss of iteration 416 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 417 -----> 99.375000 \n",
      "loss of iteration 417 is 0.625000 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 418 -----> 99.687500 \n",
      "loss of iteration 418 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 419 -----> 99.583333 \n",
      "loss of iteration 419 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 420 -----> 99.479167 \n",
      "loss of iteration 420 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 421 -----> 99.687500 \n",
      "loss of iteration 421 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 422 -----> 99.479167 \n",
      "loss of iteration 422 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 423 -----> 99.270833 \n",
      "loss of iteration 423 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 424 -----> 99.687500 \n",
      "loss of iteration 424 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 425 -----> 99.479167 \n",
      "loss of iteration 425 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 426 -----> 99.166667 \n",
      "loss of iteration 426 is 0.833333 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 427 -----> 99.687500 \n",
      "loss of iteration 427 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 428 -----> 99.583333 \n",
      "loss of iteration 428 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 429 -----> 99.479167 \n",
      "loss of iteration 429 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 430 -----> 99.375000 \n",
      "loss of iteration 430 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 431 -----> 99.375000 \n",
      "loss of iteration 431 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 432 -----> 99.791667 \n",
      "loss of iteration 432 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 433 -----> 99.375000 \n",
      "loss of iteration 433 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 434 -----> 99.479167 \n",
      "loss of iteration 434 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 435 -----> 99.479167 \n",
      "loss of iteration 435 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 436 -----> 99.479167 \n",
      "loss of iteration 436 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 437 -----> 99.166667 \n",
      "loss of iteration 437 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 438 -----> 99.479167 \n",
      "loss of iteration 438 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 439 -----> 99.583333 \n",
      "loss of iteration 439 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 440 -----> 99.479167 \n",
      "loss of iteration 440 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 441 -----> 99.479167 \n",
      "loss of iteration 441 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 442 -----> 99.583333 \n",
      "loss of iteration 442 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 443 -----> 99.479167 \n",
      "loss of iteration 443 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 444 -----> 99.270833 \n",
      "loss of iteration 444 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 445 -----> 99.687500 \n",
      "loss of iteration 445 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 446 -----> 99.583333 \n",
      "loss of iteration 446 is 0.416667 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 447 -----> 99.791667 \n",
      "loss of iteration 447 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 448 -----> 99.375000 \n",
      "loss of iteration 448 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 449 -----> 99.375000 \n",
      "loss of iteration 449 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 450 -----> 99.479167 \n",
      "loss of iteration 450 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 451 -----> 99.479167 \n",
      "loss of iteration 451 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 452 -----> 99.687500 \n",
      "loss of iteration 452 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 453 -----> 99.583333 \n",
      "loss of iteration 453 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 454 -----> 99.479167 \n",
      "loss of iteration 454 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 455 -----> 99.687500 \n",
      "loss of iteration 455 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 456 -----> 99.479167 \n",
      "loss of iteration 456 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 457 -----> 99.166667 \n",
      "loss of iteration 457 is 0.833333 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 458 -----> 99.583333 \n",
      "loss of iteration 458 is 0.416667 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 459 -----> 99.583333 \n",
      "loss of iteration 459 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 460 -----> 99.375000 \n",
      "loss of iteration 460 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 461 -----> 99.479167 \n",
      "loss of iteration 461 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 462 -----> 99.479167 \n",
      "loss of iteration 462 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 463 -----> 99.375000 \n",
      "loss of iteration 463 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 464 -----> 99.375000 \n",
      "loss of iteration 464 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 465 -----> 99.791667 \n",
      "loss of iteration 465 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 466 -----> 99.375000 \n",
      "loss of iteration 466 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 467 -----> 99.479167 \n",
      "loss of iteration 467 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 468 -----> 99.479167 \n",
      "loss of iteration 468 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 469 -----> 99.479167 \n",
      "loss of iteration 469 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 470 -----> 99.166667 \n",
      "loss of iteration 470 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 471 -----> 99.479167 \n",
      "loss of iteration 471 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 472 -----> 99.583333 \n",
      "loss of iteration 472 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 473 -----> 99.479167 \n",
      "loss of iteration 473 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 474 -----> 99.375000 \n",
      "loss of iteration 474 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 475 -----> 99.479167 \n",
      "loss of iteration 475 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 476 -----> 99.687500 \n",
      "loss of iteration 476 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 477 -----> 99.583333 \n",
      "loss of iteration 477 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 478 -----> 99.375000 \n",
      "loss of iteration 478 is 0.625000 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 479 -----> 99.687500 \n",
      "loss of iteration 479 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 480 -----> 99.479167 \n",
      "loss of iteration 480 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 481 -----> 99.583333 \n",
      "loss of iteration 481 is 0.416667 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 482 -----> 99.791667 \n",
      "loss of iteration 482 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 483 -----> 99.375000 \n",
      "loss of iteration 483 is 0.625000 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 484 -----> 99.166667 \n",
      "loss of iteration 484 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 485 -----> 99.479167 \n",
      "loss of iteration 485 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 486 -----> 99.375000 \n",
      "loss of iteration 486 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 487 -----> 99.479167 \n",
      "loss of iteration 487 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 488 -----> 99.687500 \n",
      "loss of iteration 488 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 489 -----> 99.583333 \n",
      "loss of iteration 489 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 490 -----> 99.375000 \n",
      "loss of iteration 490 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 491 -----> 99.583333 \n",
      "loss of iteration 491 is 0.416667 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 492 -----> 99.583333 \n",
      "loss of iteration 492 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 493 -----> 99.375000 \n",
      "loss of iteration 493 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 494 -----> 99.479167 \n",
      "loss of iteration 494 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 495 -----> 99.375000 \n",
      "loss of iteration 495 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 496 -----> 99.791667 \n",
      "loss of iteration 496 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 497 -----> 99.375000 \n",
      "loss of iteration 497 is 0.625000 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 498 -----> 99.166667 \n",
      "loss of iteration 498 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 499 -----> 99.479167 \n",
      "loss of iteration 499 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 500 -----> 99.375000 \n",
      "loss of iteration 500 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 501 -----> 99.479167 \n",
      "loss of iteration 501 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 502 -----> 99.687500 \n",
      "loss of iteration 502 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 503 -----> 99.583333 \n",
      "loss of iteration 503 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 504 -----> 99.375000 \n",
      "loss of iteration 504 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 505 -----> 99.479167 \n",
      "loss of iteration 505 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 506 -----> 99.583333 \n",
      "loss of iteration 506 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 507 -----> 99.375000 \n",
      "loss of iteration 507 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 508 -----> 99.479167 \n",
      "loss of iteration 508 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 509 -----> 99.375000 \n",
      "loss of iteration 509 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 510 -----> 99.791667 \n",
      "loss of iteration 510 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 511 -----> 99.375000 \n",
      "loss of iteration 511 is 0.625000 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 512 -----> 99.166667 \n",
      "loss of iteration 512 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 513 -----> 99.479167 \n",
      "loss of iteration 513 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 514 -----> 99.375000 \n",
      "loss of iteration 514 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 515 -----> 99.479167 \n",
      "loss of iteration 515 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 516 -----> 99.687500 \n",
      "loss of iteration 516 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 517 -----> 99.583333 \n",
      "loss of iteration 517 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 518 -----> 99.375000 \n",
      "loss of iteration 518 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 519 -----> 99.479167 \n",
      "loss of iteration 519 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 520 -----> 99.583333 \n",
      "loss of iteration 520 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 521 -----> 99.375000 \n",
      "loss of iteration 521 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 522 -----> 99.479167 \n",
      "loss of iteration 522 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 523 -----> 99.270833 \n",
      "loss of iteration 523 is 0.729167 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 524 -----> 99.375000 \n",
      "loss of iteration 524 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 525 -----> 99.791667 \n",
      "loss of iteration 525 is 0.208333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 526 -----> 99.479167 \n",
      "loss of iteration 526 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 527 -----> 99.479167 \n",
      "loss of iteration 527 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 528 -----> 99.166667 \n",
      "loss of iteration 528 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 529 -----> 99.479167 \n",
      "loss of iteration 529 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 530 -----> 99.583333 \n",
      "loss of iteration 530 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 531 -----> 99.479167 \n",
      "loss of iteration 531 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 532 -----> 99.479167 \n",
      "loss of iteration 532 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 533 -----> 99.479167 \n",
      "loss of iteration 533 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 534 -----> 99.583333 \n",
      "loss of iteration 534 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 535 -----> 99.375000 \n",
      "loss of iteration 535 is 0.625000 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 536 -----> 99.166667 \n",
      "loss of iteration 536 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 537 -----> 99.479167 \n",
      "loss of iteration 537 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 538 -----> 99.479167 \n",
      "loss of iteration 538 is 0.520833 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 539 -----> 99.791667 \n",
      "loss of iteration 539 is 0.208333 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 540 -----> 99.270833 \n",
      "loss of iteration 540 is 0.729167 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 541 -----> 99.583333 \n",
      "loss of iteration 541 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 542 -----> 99.375000 \n",
      "loss of iteration 542 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 543 -----> 99.479167 \n",
      "loss of iteration 543 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 544 -----> 99.583333 \n",
      "loss of iteration 544 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 545 -----> 99.375000 \n",
      "loss of iteration 545 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 546 -----> 99.479167 \n",
      "loss of iteration 546 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 547 -----> 99.479167 \n",
      "loss of iteration 547 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 548 -----> 99.166667 \n",
      "loss of iteration 548 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 549 -----> 99.479167 \n",
      "loss of iteration 549 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 550 -----> 99.583333 \n",
      "loss of iteration 550 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 551 -----> 99.375000 \n",
      "loss of iteration 551 is 0.625000 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 552 -----> 99.270833 \n",
      "loss of iteration 552 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 553 -----> 99.479167 \n",
      "loss of iteration 553 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 554 -----> 99.479167 \n",
      "loss of iteration 554 is 0.520833 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 555 -----> 99.791667 \n",
      "loss of iteration 555 is 0.208333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 556 -----> 99.479167 \n",
      "loss of iteration 556 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 557 -----> 99.479167 \n",
      "loss of iteration 557 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 558 -----> 99.270833 \n",
      "loss of iteration 558 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 559 -----> 99.687500 \n",
      "loss of iteration 559 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 560 -----> 99.479167 \n",
      "loss of iteration 560 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 561 -----> 99.166667 \n",
      "loss of iteration 561 is 0.833333 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 562 -----> 99.583333 \n",
      "loss of iteration 562 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 563 -----> 99.479167 \n",
      "loss of iteration 563 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 564 -----> 99.479167 \n",
      "loss of iteration 564 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 565 -----> 99.479167 \n",
      "loss of iteration 565 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 566 -----> 99.479167 \n",
      "loss of iteration 566 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 567 -----> 99.687500 \n",
      "loss of iteration 567 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 568 -----> 99.479167 \n",
      "loss of iteration 568 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 569 -----> 99.166667 \n",
      "loss of iteration 569 is 0.833333 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 570 -----> 99.583333 \n",
      "loss of iteration 570 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 571 -----> 99.375000 \n",
      "loss of iteration 571 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 572 -----> 99.583333 \n",
      "loss of iteration 572 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 573 -----> 99.479167 \n",
      "loss of iteration 573 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 574 -----> 99.583333 \n",
      "loss of iteration 574 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 575 -----> 99.479167 \n",
      "loss of iteration 575 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 576 -----> 99.270833 \n",
      "loss of iteration 576 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 577 -----> 99.687500 \n",
      "loss of iteration 577 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 578 -----> 99.479167 \n",
      "loss of iteration 578 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 579 -----> 99.166667 \n",
      "loss of iteration 579 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 580 -----> 99.479167 \n",
      "loss of iteration 580 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 581 -----> 99.583333 \n",
      "loss of iteration 581 is 0.416667 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 582 -----> 99.791667 \n",
      "loss of iteration 582 is 0.208333 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 583 -----> 99.270833 \n",
      "loss of iteration 583 is 0.729167 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 584 -----> 99.583333 \n",
      "loss of iteration 584 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 585 -----> 99.375000 \n",
      "loss of iteration 585 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 586 -----> 99.479167 \n",
      "loss of iteration 586 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 587 -----> 99.583333 \n",
      "loss of iteration 587 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 588 -----> 99.375000 \n",
      "loss of iteration 588 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 589 -----> 99.479167 \n",
      "loss of iteration 589 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 590 -----> 99.375000 \n",
      "loss of iteration 590 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 591 -----> 99.791667 \n",
      "loss of iteration 591 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 592 -----> 99.375000 \n",
      "loss of iteration 592 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 593 -----> 99.479167 \n",
      "loss of iteration 593 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 594 -----> 99.479167 \n",
      "loss of iteration 594 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 595 -----> 99.479167 \n",
      "loss of iteration 595 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 596 -----> 99.166667 \n",
      "loss of iteration 596 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 597 -----> 99.479167 \n",
      "loss of iteration 597 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 598 -----> 99.583333 \n",
      "loss of iteration 598 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 599 -----> 99.375000 \n",
      "loss of iteration 599 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 600 -----> 99.479167 \n",
      "loss of iteration 600 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 601 -----> 99.479167 \n",
      "loss of iteration 601 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 602 -----> 99.687500 \n",
      "loss of iteration 602 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 603 -----> 99.583333 \n",
      "loss of iteration 603 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 604 -----> 99.375000 \n",
      "loss of iteration 604 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 605 -----> 99.583333 \n",
      "loss of iteration 605 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 606 -----> 99.479167 \n",
      "loss of iteration 606 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 607 -----> 99.479167 \n",
      "loss of iteration 607 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 608 -----> 99.479167 \n",
      "loss of iteration 608 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 609 -----> 99.479167 \n",
      "loss of iteration 609 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 610 -----> 99.687500 \n",
      "loss of iteration 610 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 611 -----> 99.479167 \n",
      "loss of iteration 611 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 612 -----> 99.270833 \n",
      "loss of iteration 612 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 613 -----> 99.687500 \n",
      "loss of iteration 613 is 0.312500 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 614 -----> 99.270833 \n",
      "loss of iteration 614 is 0.729167 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 615 -----> 99.166667 \n",
      "loss of iteration 615 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 616 -----> 99.479167 \n",
      "loss of iteration 616 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 617 -----> 99.583333 \n",
      "loss of iteration 617 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 618 -----> 99.479167 \n",
      "loss of iteration 618 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 619 -----> 99.479167 \n",
      "loss of iteration 619 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 620 -----> 99.166667 \n",
      "loss of iteration 620 is 0.833333 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 621 -----> 99.583333 \n",
      "loss of iteration 621 is 0.416667 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 622 -----> 99.583333 \n",
      "loss of iteration 622 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 623 -----> 99.479167 \n",
      "loss of iteration 623 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 624 -----> 99.479167 \n",
      "loss of iteration 624 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 625 -----> 99.479167 \n",
      "loss of iteration 625 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 626 -----> 99.583333 \n",
      "loss of iteration 626 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 627 -----> 99.375000 \n",
      "loss of iteration 627 is 0.625000 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 628 -----> 99.166667 \n",
      "loss of iteration 628 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 629 -----> 99.479167 \n",
      "loss of iteration 629 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 630 -----> 99.583333 \n",
      "loss of iteration 630 is 0.416667 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 631 -----> 99.687500 \n",
      "loss of iteration 631 is 0.312500 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 632 -----> 99.270833 \n",
      "loss of iteration 632 is 0.729167 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 633 -----> 99.583333 \n",
      "loss of iteration 633 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 634 -----> 99.375000 \n",
      "loss of iteration 634 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 635 -----> 99.583333 \n",
      "loss of iteration 635 is 0.416667 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 636 -----> 99.583333 \n",
      "loss of iteration 636 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 637 -----> 99.375000 \n",
      "loss of iteration 637 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 638 -----> 99.479167 \n",
      "loss of iteration 638 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 639 -----> 99.479167 \n",
      "loss of iteration 639 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 640 -----> 99.375000 \n",
      "loss of iteration 640 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 641 -----> 99.375000 \n",
      "loss of iteration 641 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 642 -----> 99.791667 \n",
      "loss of iteration 642 is 0.208333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 643 -----> 99.479167 \n",
      "loss of iteration 643 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 644 -----> 99.479167 \n",
      "loss of iteration 644 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 645 -----> 99.166667 \n",
      "loss of iteration 645 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 646 -----> 99.479167 \n",
      "loss of iteration 646 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 647 -----> 99.583333 \n",
      "loss of iteration 647 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 648 -----> 99.479167 \n",
      "loss of iteration 648 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 649 -----> 99.479167 \n",
      "loss of iteration 649 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 650 -----> 99.270833 \n",
      "loss of iteration 650 is 0.729167 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 651 -----> 99.375000 \n",
      "loss of iteration 651 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 652 -----> 99.791667 \n",
      "loss of iteration 652 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 653 -----> 99.375000 \n",
      "loss of iteration 653 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 654 -----> 99.479167 \n",
      "loss of iteration 654 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 655 -----> 99.687500 \n",
      "loss of iteration 655 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 656 -----> 99.583333 \n",
      "loss of iteration 656 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 657 -----> 99.375000 \n",
      "loss of iteration 657 is 0.625000 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 658 -----> 99.687500 \n",
      "loss of iteration 658 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 659 -----> 99.583333 \n",
      "loss of iteration 659 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 660 -----> 99.375000 \n",
      "loss of iteration 660 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 661 -----> 99.479167 \n",
      "loss of iteration 661 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 662 -----> 99.375000 \n",
      "loss of iteration 662 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 663 -----> 99.791667 \n",
      "loss of iteration 663 is 0.208333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 664 -----> 99.479167 \n",
      "loss of iteration 664 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 665 -----> 99.479167 \n",
      "loss of iteration 665 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 666 -----> 99.375000 \n",
      "loss of iteration 666 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 667 -----> 99.479167 \n",
      "loss of iteration 667 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 668 -----> 99.166667 \n",
      "loss of iteration 668 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 669 -----> 99.479167 \n",
      "loss of iteration 669 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 670 -----> 99.583333 \n",
      "loss of iteration 670 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 671 -----> 99.479167 \n",
      "loss of iteration 671 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 672 -----> 99.479167 \n",
      "loss of iteration 672 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 673 -----> 99.270833 \n",
      "loss of iteration 673 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 674 -----> 99.687500 \n",
      "loss of iteration 674 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 675 -----> 99.479167 \n",
      "loss of iteration 675 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 676 -----> 99.270833 \n",
      "loss of iteration 676 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 677 -----> 99.687500 \n",
      "loss of iteration 677 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 678 -----> 99.479167 \n",
      "loss of iteration 678 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 679 -----> 99.166667 \n",
      "loss of iteration 679 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 680 -----> 99.479167 \n",
      "loss of iteration 680 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 681 -----> 99.583333 \n",
      "loss of iteration 681 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 682 -----> 99.479167 \n",
      "loss of iteration 682 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 683 -----> 99.687500 \n",
      "loss of iteration 683 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 684 -----> 99.583333 \n",
      "loss of iteration 684 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 685 -----> 99.375000 \n",
      "loss of iteration 685 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 686 -----> 99.583333 \n",
      "loss of iteration 686 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 687 -----> 99.479167 \n",
      "loss of iteration 687 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 688 -----> 99.479167 \n",
      "loss of iteration 688 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 689 -----> 99.479167 \n",
      "loss of iteration 689 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 690 -----> 99.479167 \n",
      "loss of iteration 690 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 691 -----> 99.270833 \n",
      "loss of iteration 691 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 692 -----> 99.479167 \n",
      "loss of iteration 692 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 693 -----> 99.583333 \n",
      "loss of iteration 693 is 0.416667 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 694 -----> 99.791667 \n",
      "loss of iteration 694 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 695 -----> 99.375000 \n",
      "loss of iteration 695 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 696 -----> 99.479167 \n",
      "loss of iteration 696 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 697 -----> 99.479167 \n",
      "loss of iteration 697 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 698 -----> 99.166667 \n",
      "loss of iteration 698 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 699 -----> 99.479167 \n",
      "loss of iteration 699 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 700 -----> 99.583333 \n",
      "loss of iteration 700 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 701 -----> 99.479167 \n",
      "loss of iteration 701 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 702 -----> 99.479167 \n",
      "loss of iteration 702 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 703 -----> 99.270833 \n",
      "loss of iteration 703 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 704 -----> 99.687500 \n",
      "loss of iteration 704 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 705 -----> 99.479167 \n",
      "loss of iteration 705 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 706 -----> 99.270833 \n",
      "loss of iteration 706 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 707 -----> 99.687500 \n",
      "loss of iteration 707 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 708 -----> 99.479167 \n",
      "loss of iteration 708 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 709 -----> 99.166667 \n",
      "loss of iteration 709 is 0.833333 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 710 -----> 99.583333 \n",
      "loss of iteration 710 is 0.416667 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 711 -----> 99.583333 \n",
      "loss of iteration 711 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 712 -----> 99.479167 \n",
      "loss of iteration 712 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 713 -----> 99.479167 \n",
      "loss of iteration 713 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 714 -----> 99.479167 \n",
      "loss of iteration 714 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 715 -----> 99.583333 \n",
      "loss of iteration 715 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 716 -----> 99.375000 \n",
      "loss of iteration 716 is 0.625000 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 717 -----> 99.166667 \n",
      "loss of iteration 717 is 0.833333 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 718 -----> 99.583333 \n",
      "loss of iteration 718 is 0.416667 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 719 -----> 99.687500 \n",
      "loss of iteration 719 is 0.312500 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 720 -----> 99.375000 \n",
      "loss of iteration 720 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 721 -----> 99.791667 \n",
      "loss of iteration 721 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 722 -----> 99.375000 \n",
      "loss of iteration 722 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 723 -----> 99.479167 \n",
      "loss of iteration 723 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 724 -----> 99.375000 \n",
      "loss of iteration 724 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 725 -----> 99.791667 \n",
      "loss of iteration 725 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 726 -----> 99.375000 \n",
      "loss of iteration 726 is 0.625000 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 727 -----> 99.166667 \n",
      "loss of iteration 727 is 0.833333 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 728 -----> 99.583333 \n",
      "loss of iteration 728 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 729 -----> 99.479167 \n",
      "loss of iteration 729 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 730 -----> 99.583333 \n",
      "loss of iteration 730 is 0.416667 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 731 -----> 99.791667 \n",
      "loss of iteration 731 is 0.208333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 732 -----> 99.479167 \n",
      "loss of iteration 732 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 733 -----> 99.479167 \n",
      "loss of iteration 733 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 734 -----> 99.270833 \n",
      "loss of iteration 734 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 735 -----> 99.687500 \n",
      "loss of iteration 735 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 736 -----> 99.479167 \n",
      "loss of iteration 736 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 737 -----> 99.270833 \n",
      "loss of iteration 737 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 738 -----> 99.687500 \n",
      "loss of iteration 738 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 739 -----> 99.479167 \n",
      "loss of iteration 739 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 740 -----> 99.166667 \n",
      "loss of iteration 740 is 0.833333 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 741 -----> 99.583333 \n",
      "loss of iteration 741 is 0.416667 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 742 -----> 99.583333 \n",
      "loss of iteration 742 is 0.416667 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 743 -----> 99.687500 \n",
      "loss of iteration 743 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 744 -----> 99.583333 \n",
      "loss of iteration 744 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 745 -----> 99.479167 \n",
      "loss of iteration 745 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 746 -----> 99.270833 \n",
      "loss of iteration 746 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 747 -----> 99.687500 \n",
      "loss of iteration 747 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 748 -----> 99.479167 \n",
      "loss of iteration 748 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 749 -----> 99.270833 \n",
      "loss of iteration 749 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 750 -----> 99.687500 \n",
      "loss of iteration 750 is 0.312500 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 751 -----> 99.270833 \n",
      "loss of iteration 751 is 0.729167 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 752 -----> 99.270833 \n",
      "loss of iteration 752 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 753 -----> 99.479167 \n",
      "loss of iteration 753 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 754 -----> 99.687500 \n",
      "loss of iteration 754 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 755 -----> 99.479167 \n",
      "loss of iteration 755 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 756 -----> 99.270833 \n",
      "loss of iteration 756 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 757 -----> 99.687500 \n",
      "loss of iteration 757 is 0.312500 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 758 -----> 99.270833 \n",
      "loss of iteration 758 is 0.729167 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 759 -----> 99.375000 \n",
      "loss of iteration 759 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 760 -----> 99.375000 \n",
      "loss of iteration 760 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 761 -----> 99.791667 \n",
      "loss of iteration 761 is 0.208333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 762 -----> 99.479167 \n",
      "loss of iteration 762 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 763 -----> 99.479167 \n",
      "loss of iteration 763 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 764 -----> 99.166667 \n",
      "loss of iteration 764 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 765 -----> 99.479167 \n",
      "loss of iteration 765 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 766 -----> 99.583333 \n",
      "loss of iteration 766 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 767 -----> 99.479167 \n",
      "loss of iteration 767 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 768 -----> 99.479167 \n",
      "loss of iteration 768 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 769 -----> 99.270833 \n",
      "loss of iteration 769 is 0.729167 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 770 -----> 99.375000 \n",
      "loss of iteration 770 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 771 -----> 99.791667 \n",
      "loss of iteration 771 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 772 -----> 99.375000 \n",
      "loss of iteration 772 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 773 -----> 99.479167 \n",
      "loss of iteration 773 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 774 -----> 99.687500 \n",
      "loss of iteration 774 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 775 -----> 99.583333 \n",
      "loss of iteration 775 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 776 -----> 99.375000 \n",
      "loss of iteration 776 is 0.625000 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 777 -----> 99.687500 \n",
      "loss of iteration 777 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 778 -----> 99.479167 \n",
      "loss of iteration 778 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 779 -----> 99.583333 \n",
      "loss of iteration 779 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 780 -----> 99.375000 \n",
      "loss of iteration 780 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 781 -----> 99.583333 \n",
      "loss of iteration 781 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 782 -----> 99.479167 \n",
      "loss of iteration 782 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 783 -----> 99.479167 \n",
      "loss of iteration 783 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 784 -----> 99.375000 \n",
      "loss of iteration 784 is 0.625000 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 785 -----> 99.687500 \n",
      "loss of iteration 785 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 786 -----> 99.583333 \n",
      "loss of iteration 786 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 787 -----> 99.479167 \n",
      "loss of iteration 787 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 788 -----> 99.270833 \n",
      "loss of iteration 788 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 789 -----> 99.687500 \n",
      "loss of iteration 789 is 0.312500 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 790 -----> 99.270833 \n",
      "loss of iteration 790 is 0.729167 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 791 -----> 99.270833 \n",
      "loss of iteration 791 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 792 -----> 99.479167 \n",
      "loss of iteration 792 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 793 -----> 99.687500 \n",
      "loss of iteration 793 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 794 -----> 99.479167 \n",
      "loss of iteration 794 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 795 -----> 99.270833 \n",
      "loss of iteration 795 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 796 -----> 99.687500 \n",
      "loss of iteration 796 is 0.312500 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 797 -----> 99.270833 \n",
      "loss of iteration 797 is 0.729167 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 798 -----> 99.375000 \n",
      "loss of iteration 798 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 799 -----> 99.375000 \n",
      "loss of iteration 799 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 800 -----> 99.791667 \n",
      "loss of iteration 800 is 0.208333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 801 -----> 99.479167 \n",
      "loss of iteration 801 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 802 -----> 99.479167 \n",
      "loss of iteration 802 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 803 -----> 99.166667 \n",
      "loss of iteration 803 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 804 -----> 99.479167 \n",
      "loss of iteration 804 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 805 -----> 99.583333 \n",
      "loss of iteration 805 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 806 -----> 99.479167 \n",
      "loss of iteration 806 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 807 -----> 99.479167 \n",
      "loss of iteration 807 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 808 -----> 99.270833 \n",
      "loss of iteration 808 is 0.729167 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 809 -----> 99.375000 \n",
      "loss of iteration 809 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 810 -----> 99.791667 \n",
      "loss of iteration 810 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 811 -----> 99.375000 \n",
      "loss of iteration 811 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 812 -----> 99.479167 \n",
      "loss of iteration 812 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 813 -----> 99.687500 \n",
      "loss of iteration 813 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 814 -----> 99.583333 \n",
      "loss of iteration 814 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 815 -----> 99.375000 \n",
      "loss of iteration 815 is 0.625000 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 816 -----> 99.687500 \n",
      "loss of iteration 816 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 817 -----> 99.479167 \n",
      "loss of iteration 817 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 818 -----> 99.583333 \n",
      "loss of iteration 818 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 819 -----> 99.375000 \n",
      "loss of iteration 819 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 820 -----> 99.583333 \n",
      "loss of iteration 820 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 821 -----> 99.479167 \n",
      "loss of iteration 821 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 822 -----> 99.479167 \n",
      "loss of iteration 822 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 823 -----> 99.375000 \n",
      "loss of iteration 823 is 0.625000 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 824 -----> 99.687500 \n",
      "loss of iteration 824 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 825 -----> 99.583333 \n",
      "loss of iteration 825 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 826 -----> 99.479167 \n",
      "loss of iteration 826 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 827 -----> 99.270833 \n",
      "loss of iteration 827 is 0.729167 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 828 -----> 99.583333 \n",
      "loss of iteration 828 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 829 -----> 99.375000 \n",
      "loss of iteration 829 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 830 -----> 99.583333 \n",
      "loss of iteration 830 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 831 -----> 99.479167 \n",
      "loss of iteration 831 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 832 -----> 99.479167 \n",
      "loss of iteration 832 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 833 -----> 99.479167 \n",
      "loss of iteration 833 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 834 -----> 99.479167 \n",
      "loss of iteration 834 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 835 -----> 99.479167 \n",
      "loss of iteration 835 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 836 -----> 99.687500 \n",
      "loss of iteration 836 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 837 -----> 99.479167 \n",
      "loss of iteration 837 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 838 -----> 99.479167 \n",
      "loss of iteration 838 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 839 -----> 99.375000 \n",
      "loss of iteration 839 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 840 -----> 99.791667 \n",
      "loss of iteration 840 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 841 -----> 99.375000 \n",
      "loss of iteration 841 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 842 -----> 99.791667 \n",
      "loss of iteration 842 is 0.208333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 843 -----> 99.479167 \n",
      "loss of iteration 843 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 844 -----> 99.479167 \n",
      "loss of iteration 844 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 845 -----> 99.375000 \n",
      "loss of iteration 845 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 846 -----> 99.479167 \n",
      "loss of iteration 846 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 847 -----> 99.166667 \n",
      "loss of iteration 847 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 848 -----> 99.479167 \n",
      "loss of iteration 848 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 849 -----> 99.583333 \n",
      "loss of iteration 849 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 850 -----> 99.479167 \n",
      "loss of iteration 850 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 851 -----> 99.479167 \n",
      "loss of iteration 851 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 852 -----> 99.270833 \n",
      "loss of iteration 852 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 853 -----> 99.687500 \n",
      "loss of iteration 853 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 854 -----> 99.479167 \n",
      "loss of iteration 854 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 855 -----> 99.270833 \n",
      "loss of iteration 855 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 856 -----> 99.687500 \n",
      "loss of iteration 856 is 0.312500 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 857 -----> 99.270833 \n",
      "loss of iteration 857 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 858 -----> 99.479167 \n",
      "loss of iteration 858 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 859 -----> 99.479167 \n",
      "loss of iteration 859 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 860 -----> 99.479167 \n",
      "loss of iteration 860 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 861 -----> 99.583333 \n",
      "loss of iteration 861 is 0.416667 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 862 -----> 99.270833 \n",
      "loss of iteration 862 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 863 -----> 99.479167 \n",
      "loss of iteration 863 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 864 -----> 99.583333 \n",
      "loss of iteration 864 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 865 -----> 99.375000 \n",
      "loss of iteration 865 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 866 -----> 99.791667 \n",
      "loss of iteration 866 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 867 -----> 99.375000 \n",
      "loss of iteration 867 is 0.625000 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 868 -----> 99.166667 \n",
      "loss of iteration 868 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 869 -----> 99.479167 \n",
      "loss of iteration 869 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 870 -----> 99.583333 \n",
      "loss of iteration 870 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 871 -----> 99.479167 \n",
      "loss of iteration 871 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 872 -----> 99.375000 \n",
      "loss of iteration 872 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 873 -----> 99.375000 \n",
      "loss of iteration 873 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 874 -----> 99.375000 \n",
      "loss of iteration 874 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 875 -----> 99.479167 \n",
      "loss of iteration 875 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 876 -----> 99.479167 \n",
      "loss of iteration 876 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 877 -----> 99.583333 \n",
      "loss of iteration 877 is 0.416667 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 878 -----> 99.791667 \n",
      "loss of iteration 878 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 879 -----> 99.375000 \n",
      "loss of iteration 879 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 880 -----> 99.479167 \n",
      "loss of iteration 880 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 881 -----> 99.375000 \n",
      "loss of iteration 881 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 882 -----> 99.375000 \n",
      "loss of iteration 882 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 883 -----> 99.583333 \n",
      "loss of iteration 883 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 884 -----> 99.479167 \n",
      "loss of iteration 884 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 885 -----> 99.583333 \n",
      "loss of iteration 885 is 0.416667 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 886 -----> 99.791667 \n",
      "loss of iteration 886 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 887 -----> 99.375000 \n",
      "loss of iteration 887 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 888 -----> 99.479167 \n",
      "loss of iteration 888 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 889 -----> 99.479167 \n",
      "loss of iteration 889 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 890 -----> 99.479167 \n",
      "loss of iteration 890 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 891 -----> 99.166667 \n",
      "loss of iteration 891 is 0.833333 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 892 -----> 99.583333 \n",
      "loss of iteration 892 is 0.416667 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 893 -----> 99.583333 \n",
      "loss of iteration 893 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 894 -----> 99.479167 \n",
      "loss of iteration 894 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 895 -----> 99.479167 \n",
      "loss of iteration 895 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 896 -----> 99.270833 \n",
      "loss of iteration 896 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 897 -----> 99.687500 \n",
      "loss of iteration 897 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 898 -----> 99.479167 \n",
      "loss of iteration 898 is 0.520833 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 899 -----> 99.166667 \n",
      "loss of iteration 899 is 0.833333 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 900 -----> 99.583333 \n",
      "loss of iteration 900 is 0.416667 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 901 -----> 99.583333 \n",
      "loss of iteration 901 is 0.416667 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 902 -----> 99.687500 \n",
      "loss of iteration 902 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 903 -----> 99.583333 \n",
      "loss of iteration 903 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 904 -----> 99.479167 \n",
      "loss of iteration 904 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 905 -----> 99.270833 \n",
      "loss of iteration 905 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 906 -----> 99.687500 \n",
      "loss of iteration 906 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 907 -----> 99.479167 \n",
      "loss of iteration 907 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 908 -----> 99.270833 \n",
      "loss of iteration 908 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 909 -----> 99.687500 \n",
      "loss of iteration 909 is 0.312500 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 910 -----> 99.270833 \n",
      "loss of iteration 910 is 0.729167 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 911 -----> 99.270833 \n",
      "loss of iteration 911 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 912 -----> 99.479167 \n",
      "loss of iteration 912 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 913 -----> 99.687500 \n",
      "loss of iteration 913 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 914 -----> 99.479167 \n",
      "loss of iteration 914 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 915 -----> 99.270833 \n",
      "loss of iteration 915 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 916 -----> 99.687500 \n",
      "loss of iteration 916 is 0.312500 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 917 -----> 99.270833 \n",
      "loss of iteration 917 is 0.729167 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 918 -----> 99.375000 \n",
      "loss of iteration 918 is 0.625000 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 919 -----> 99.687500 \n",
      "loss of iteration 919 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 920 -----> 99.583333 \n",
      "loss of iteration 920 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 921 -----> 99.479167 \n",
      "loss of iteration 921 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 922 -----> 99.270833 \n",
      "loss of iteration 922 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 923 -----> 99.479167 \n",
      "loss of iteration 923 is 0.520833 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 924 -----> 99.687500 \n",
      "loss of iteration 924 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 925 -----> 99.479167 \n",
      "loss of iteration 925 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 926 -----> 99.583333 \n",
      "loss of iteration 926 is 0.416667 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 927 -----> 99.791667 \n",
      "loss of iteration 927 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 928 -----> 99.375000 \n",
      "loss of iteration 928 is 0.625000 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 929 -----> 99.479167 \n",
      "loss of iteration 929 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 930 -----> 99.375000 \n",
      "loss of iteration 930 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 931 -----> 99.791667 \n",
      "loss of iteration 931 is 0.208333 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 932 -----> 99.270833 \n",
      "loss of iteration 932 is 0.729167 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 933 -----> 99.583333 \n",
      "loss of iteration 933 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 934 -----> 99.375000 \n",
      "loss of iteration 934 is 0.625000 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 935 -----> 99.687500 \n",
      "loss of iteration 935 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 936 -----> 99.479167 \n",
      "loss of iteration 936 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 937 -----> 99.479167 \n",
      "loss of iteration 937 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 938 -----> 99.479167 \n",
      "loss of iteration 938 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 939 -----> 99.479167 \n",
      "loss of iteration 939 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 940 -----> 99.270833 \n",
      "loss of iteration 940 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 941 -----> 99.479167 \n",
      "loss of iteration 941 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 942 -----> 99.583333 \n",
      "loss of iteration 942 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 943 -----> 99.375000 \n",
      "loss of iteration 943 is 0.625000 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 944 -----> 99.583333 \n",
      "loss of iteration 944 is 0.416667 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 945 -----> 99.687500 \n",
      "loss of iteration 945 is 0.312500 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 946 -----> 99.270833 \n",
      "loss of iteration 946 is 0.729167 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 947 -----> 99.375000 \n",
      "loss of iteration 947 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 948 -----> 99.375000 \n",
      "loss of iteration 948 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 949 -----> 99.791667 \n",
      "loss of iteration 949 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 950 -----> 99.375000 \n",
      "loss of iteration 950 is 0.625000 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 951 -----> 99.166667 \n",
      "loss of iteration 951 is 0.833333 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 952 -----> 99.583333 \n",
      "loss of iteration 952 is 0.416667 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 953 -----> 99.583333 \n",
      "loss of iteration 953 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 954 -----> 99.375000 \n",
      "loss of iteration 954 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 955 -----> 99.791667 \n",
      "loss of iteration 955 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 956 -----> 99.375000 \n",
      "loss of iteration 956 is 0.625000 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 957 -----> 99.166667 \n",
      "loss of iteration 957 is 0.833333 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 958 -----> 99.583333 \n",
      "loss of iteration 958 is 0.416667 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 959 -----> 99.583333 \n",
      "loss of iteration 959 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 960 -----> 99.479167 \n",
      "loss of iteration 960 is 0.520833 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 961 -----> 99.375000 \n",
      "loss of iteration 961 is 0.625000 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 962 -----> 99.687500 \n",
      "loss of iteration 962 is 0.312500 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 963 -----> 99.583333 \n",
      "loss of iteration 963 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 964 -----> 99.479167 \n",
      "loss of iteration 964 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 965 -----> 99.270833 \n",
      "loss of iteration 965 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 966 -----> 99.687500 \n",
      "loss of iteration 966 is 0.312500 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 967 -----> 99.270833 \n",
      "loss of iteration 967 is 0.729167 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 968 -----> 99.270833 \n",
      "loss of iteration 968 is 0.729167 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 969 -----> 99.583333 \n",
      "loss of iteration 969 is 0.416667 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 970 -----> 99.687500 \n",
      "loss of iteration 970 is 0.312500 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 971 -----> 99.479167 \n",
      "loss of iteration 971 is 0.520833 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 972 -----> 99.270833 \n",
      "loss of iteration 972 is 0.729167 \n",
      "\n",
      "no of misses are %d 3\n",
      "accuracy of iteration 973 -----> 99.687500 \n",
      "loss of iteration 973 is 0.312500 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 974 -----> 99.270833 \n",
      "loss of iteration 974 is 0.729167 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 975 -----> 99.375000 \n",
      "loss of iteration 975 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 976 -----> 99.375000 \n",
      "loss of iteration 976 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 977 -----> 99.791667 \n",
      "loss of iteration 977 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 978 -----> 99.375000 \n",
      "loss of iteration 978 is 0.625000 \n",
      "\n",
      "no of misses are %d 8\n",
      "accuracy of iteration 979 -----> 99.166667 \n",
      "loss of iteration 979 is 0.833333 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 980 -----> 99.479167 \n",
      "loss of iteration 980 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 981 -----> 99.479167 \n",
      "loss of iteration 981 is 0.520833 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 982 -----> 99.791667 \n",
      "loss of iteration 982 is 0.208333 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 983 -----> 99.375000 \n",
      "loss of iteration 983 is 0.625000 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 984 -----> 99.375000 \n",
      "loss of iteration 984 is 0.625000 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 985 -----> 99.270833 \n",
      "loss of iteration 985 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 986 -----> 99.479167 \n",
      "loss of iteration 986 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 987 -----> 99.583333 \n",
      "loss of iteration 987 is 0.416667 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 988 -----> 99.479167 \n",
      "loss of iteration 988 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 989 -----> 99.479167 \n",
      "loss of iteration 989 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 990 -----> 99.479167 \n",
      "loss of iteration 990 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 991 -----> 99.479167 \n",
      "loss of iteration 991 is 0.520833 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 992 -----> 99.479167 \n",
      "loss of iteration 992 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 993 -----> 99.583333 \n",
      "loss of iteration 993 is 0.416667 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 994 -----> 99.270833 \n",
      "loss of iteration 994 is 0.729167 \n",
      "\n",
      "no of misses are %d 5\n",
      "accuracy of iteration 995 -----> 99.479167 \n",
      "loss of iteration 995 is 0.520833 \n",
      "\n",
      "no of misses are %d 4\n",
      "accuracy of iteration 996 -----> 99.583333 \n",
      "loss of iteration 996 is 0.416667 \n",
      "\n",
      "no of misses are %d 6\n",
      "accuracy of iteration 997 -----> 99.375000 \n",
      "loss of iteration 997 is 0.625000 \n",
      "\n",
      "no of misses are %d 2\n",
      "accuracy of iteration 998 -----> 99.791667 \n",
      "loss of iteration 998 is 0.208333 \n",
      "\n",
      "no of misses are %d 7\n",
      "accuracy of iteration 999 -----> 99.270833 \n",
      "loss of iteration 999 is 0.729167 \n",
      "\n",
      "75.0\n",
      "-60.571182749995145\n",
      "-38.49601999999878\n",
      "-42.97683199999975\n",
      "-10.825374500000374\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-edf537b5-9d11-4f50-af53-7baacc4a7ae4\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-edf537b5-9d11-4f50-af53-7baacc4a7ae4\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_34f88ad4-0fd0-4224-8aa1-3f869bf3d77b\", \"test2.json\", 14905)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing test accuracy\n",
      "98.05825242718447\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "\n",
    "data =pd.read_csv('train2.txt',header=None,sep=\" \")\n",
    "#print(data)\n",
    "Y_train=list()\n",
    "#print(Y_train)\n",
    "print(\"yes\")\n",
    "X=[]\n",
    "temp=[]\n",
    "\n",
    "rows=len(data)\n",
    "cols=len(data.columns)\n",
    "\n",
    "X_train=list(list())\n",
    "z=[[]*(cols-1)]*(rows)\n",
    "\n",
    "#convert string data to float\n",
    "for i in range(cols):\n",
    "  data[i]=data[i].astype(float)\n",
    "\n",
    "\n",
    "\n",
    "data.to_json(r'train2.json',orient='values')\n",
    "files.download('train2.json')\n",
    "\n",
    "\"\"\"for i in range(rows):\n",
    "  for j in range(cols):\n",
    "    print(data[i][j])\"\"\"\n",
    "\n",
    "\n",
    "with open('train2.json') as f:\n",
    "  X= json.load(f)\n",
    "#print(X)\n",
    "X_train=X\n",
    "for i in range(rows):\n",
    "    Y_train.append(X[i][cols-1])\n",
    "\n",
    "#for i in X_train:\n",
    "#  del i[cols-1]\n",
    "\n",
    "print(X)\n",
    "print(Y_train)    \n",
    "\n",
    "#making X and Y are done\n",
    "#import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# notice that you should run it only with python3\n",
    "\"\"\" define a class to generate weights for perceptron\"\"\"\n",
    "\n",
    "class Perceptron(object):\n",
    "\n",
    "    def __init__(self, no_of_inputs, lr_rate=0.5, bios_lr_rate=0.5):\n",
    "    #\"\"\"\n",
    "    # @param: the object of perceptron,no of inputs,learning rate,bios_learning rate\n",
    "    # returns : initialises the object with the given parameters\n",
    "    #\"\"\"\n",
    "\n",
    "        # self.threshold = threshold\n",
    "        self.lr_rate = lr_rate\n",
    "        self.bios_lr_rate = bios_lr_rate\n",
    "        self.weights = [0.0,0.0,0.0,0.0,0.0]\n",
    "           \n",
    "    def getter(self):\n",
    "      #\"\"\"@param : object of perceptron class\n",
    "      #    returns: vector of weights\"\"\"\n",
    "        return self.weights\n",
    "\n",
    "    def train(self, training_inputs, target):\n",
    "      #\"\"\"@param : object of perceptron, X-vector, target value\n",
    "      #  role : alters the weights and uses stochastic gradient descent approach to find the optimal weights\n",
    "      #  returns : the predicted value of target\"\"\"\n",
    "        # print(training_inputs)\n",
    "        group1_x  = training_inputs[0]\n",
    "        x2 = training_inputs[1]\n",
    "        x3 = training_inputs[2]\n",
    "        x4 = training_inputs[3]\n",
    "        b = self.weights[4]\n",
    "        w1 = self.weights[0]\n",
    "        w2 = self.weights[1]\n",
    "        w3 = self.weights[2]\n",
    "        w4 = self.weights[3]\n",
    "        \n",
    "        y = b + group1_x * w1 + x2 * w2 + x3*w3 + x4*w4\n",
    "\n",
    "        if y > 0:\n",
    "            y = 1.0\n",
    "        else:\n",
    "            y = 0.0\n",
    "        self.weights[4] = b + self.bios_lr_rate * (target - y)\n",
    "        self.weights[3] = w4 + self.lr_rate * (target - y)*x4\n",
    "        self.weights[2] = w3 + self.lr_rate * (target - y)*x3\n",
    "        self.weights[0] = w1 + self.lr_rate * (target - y) * group1_x\n",
    "        self.weights[1] = w2 + self.lr_rate * (target - y) * x2\n",
    "        return y\n",
    "\n",
    "\n",
    "network = Perceptron(4)\n",
    "training_inputs = []\n",
    "label = []\n",
    "group0_x = []\n",
    "group0_y = []\n",
    "group1_x = []\n",
    "group1_y = []\n",
    "iterations = 5000\n",
    "num_of_miss = {}\n",
    "accuracy_of_each_iteration = {}\n",
    "miss = 0\n",
    "\"\"\" Run the updated training weights on each point and find for missclassifications and alter the weights until you reach zero missclassifications\"\"\"\n",
    "for i in range(iterations):\n",
    "\n",
    "        for row in X:\n",
    "            training_inputs = [float(row[0]),float(row[1]),float(row[2]),float(row[3])]\n",
    "            label = float(row[4])\n",
    "            prediction = network.train(training_inputs, label)\n",
    "            if prediction != label:\n",
    "                miss += 1\n",
    "    \n",
    "            if label == 1.0:\n",
    "              #\"\"\"when you find the positive point , append it to the positive group\"\"\"\n",
    "                group1_x.append(float(row[0]))\n",
    "                group1_y.append(float(row[1]))\n",
    "            if label == 0.0:\n",
    "              #\"\"\"when you find the negative point , append it to the negative group\"\"\"\n",
    "                group0_x.append(float(row[0]))\n",
    "                group0_y.append(float(row[1]))\n",
    "        print(\"no of misses are %d\",miss)\n",
    "        #\"\"\"update the number of misses for each iteration\"\"\"\n",
    "        num_of_miss[i] = miss\n",
    "        #\"\"\"terminating or converging condition is reached when all the points are classified correctly\"\"\"\n",
    "        if num_of_miss[i]==0:\n",
    "          #print(\"linearly separable at iteration %d\",i)\n",
    "          break\n",
    "        accuracy_of_each_iteration[i] = ((rows-num_of_miss[i])/rows)*100\n",
    "        print(\"accuracy of iteration %d -----> %f \"%(i,accuracy_of_each_iteration[i]))\n",
    "        print(\"loss of iteration %d is %f \"%(i,(((num_of_miss[i])/rows)*100)))\n",
    "        print()\n",
    "        miss = 0\n",
    "\n",
    "\n",
    "\n",
    "weights = network.getter()\n",
    "w1 = weights[0]\n",
    "w2 = weights[1]\n",
    "w3 = weights[2]\n",
    "w4 = weights[3]\n",
    "b = weights[4]\n",
    "\n",
    "print(b)\n",
    "print(w1)\n",
    "print(w2)\n",
    "print(w3)\n",
    "print(w4)\n",
    "\n",
    "test_data =pd.read_csv('test2.txt',header=None,sep=\" \")\n",
    "files.upload()\n",
    "\n",
    "test_rows=len(test_data)\n",
    "test_cols=len(test_data.columns)\n",
    "\n",
    "#convert string data to float\n",
    "for i in range(test_cols):\n",
    "  test_data[i]=test_data[i].astype(float)\n",
    "\n",
    "\n",
    "\n",
    "test_data.to_json(r'test2.json',orient='values')\n",
    "files.download('test2.json')\n",
    "\n",
    "\"\"\"for i in range(rows):\n",
    "  for j in range(cols):\n",
    "    print(data[i][j])\"\"\"\n",
    "\n",
    "\n",
    "with open('test2.json') as f1:\n",
    "  test_X= json.load(f1)\n",
    "\n",
    "#files.download('test1.json')\n",
    "\n",
    "test_miss=0\n",
    "\n",
    "for row in test_X:\n",
    "    y1 = b + float(row[0])*w1 + float(row[1])*w2 + float(row[2])*w3 + float(row[3])*w4\n",
    "\n",
    "    if y1 > 0:\n",
    "      y1 = 1.0\n",
    "    else:\n",
    "      y1 = 0.0\n",
    "    \n",
    "    label1=float(row[4])\n",
    "    if y1 != label1:\n",
    "      test_miss = test_miss+1\n",
    "\n",
    "test_accuracy=(test_rows-test_miss)*100/test_rows\n",
    "print(\"printing test accuracy\")\n",
    "print(test_accuracy)\n",
    "        \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIGZocc_nfca"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Perceptron_dataset_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
